{
    "timers": {
        "training_iteration": 42.15259092399356,
        "restore_env_runners": 3.9341000956483185e-05,
        "training_step": 42.15221480299806,
        "env_runner_sampling_timer": 1.118392094002047,
        "learner_update_timer": 40.92267430599895,
        "synch_weights": 0.00309701500373194
    },
    "env_runners": {
        "env_to_module_connector": {
            "timers": {
                "connectors": {
                    "batch_individual_items": 4.745802864526564e-05,
                    "numpy_to_tensor": 7.694554140951274e-05,
                    "add_states_from_episodes_to_batch": 8.749267582972687e-06,
                    "add_observations_from_episodes_to_batch": 1.0874719005420258e-05,
                    "add_time_dim_to_batch_and_zero_pad": 2.8997959745158537e-05
                }
            },
            "connector_pipeline_timer": 0.000282479444258379
        },
        "rlmodule_inference_timer": 0.0002604704982935833,
        "sample": 0.023736736490335753,
        "num_module_steps_sampled_lifetime": {
            "default_policy": 21582.0
        },
        "module_episode_returns_mean": {
            "default_policy": 22.769047619047623
        },
        "time_between_sampling": 0.001310647990845806,
        "num_episodes_lifetime": 990.0,
        "num_env_steps_sampled": 1007.9999999999999,
        "num_agent_steps_sampled": {
            "default_agent": 1007.9999999999999
        },
        "episode_len_max": 74,
        "module_to_env_connector": {
            "timers": {
                "connectors": {
                    "remove_single_ts_time_rank_from_batch": 3.660820439965988e-05,
                    "normalize_and_clip_actions": 8.636905197990241e-05,
                    "listify_data_for_vector_env": 4.015145381220535e-05,
                    "un_batch_to_individual_items": 2.2731344265805597e-05,
                    "get_actions": 0.0003426156930828549,
                    "tensor_to_numpy": 7.035591278091705e-05
                }
            },
            "connector_pipeline_timer": 0.0007050867285719815
        },
        "env_to_module_sum_episodes_length_in": 13.236945796656777,
        "num_agent_steps_sampled_lifetime": {
            "default_agent": 21582.0
        },
        "env_to_module_sum_episodes_length_out": 13.236945796656777,
        "episode_return_max": 74.0,
        "episode_duration_sec_mean": 0.02312117942148082,
        "episode_len_min": 10,
        "episode_len_mean": 22.769047619047623,
        "agent_episode_returns_mean": {
            "default_agent": 22.769047619047623
        },
        "num_env_steps_sampled_lifetime": 21582.0,
        "num_module_steps_sampled": {
            "default_policy": 1007.9999999999999
        },
        "weights_seq_no": 0.0,
        "episode_return_min": 10.0,
        "episode_return_mean": 22.769047619047623,
        "num_episodes": 44.0,
        "env_step_timer": 0.00010732240234175793,
        "env_reset_timer": 0.0004886164557351027,
        "num_env_steps_sampled_lifetime_throughput": 644.9688581176808
    },
    "__all_modules__": {
        "learner_connector_sum_episodes_length_in": 1008,
        "learner_connector": {
            "connector_pipeline_timer": 0.08789512500516139,
            "timers": {
                "connectors": {
                    "add_one_ts_to_episodes_and_truncate": 0.006145055005617905,
                    "add_observations_from_episodes_to_batch": 0.0006341789994621649,
                    "add_columns_from_episodes_to_train_batch": 0.019577286999265198,
                    "add_time_dim_to_batch_and_zero_pad": 0.05841322900232626,
                    "add_states_from_episodes_to_batch": 0.0013313240051502362,
                    "batch_individual_items": 0.001191442999697756,
                    "numpy_to_tensor": 0.0001793490009731613
                }
            }
        },
        "learner_connector_sum_episodes_length_out": 1052
    },
    "learners": {
        "default_policy": {
            "diff_num_grad_updates_vs_sampler_policy": 1.0,
            "num_trainable_parameters": 16003,
            "num_module_steps_trained_lifetime": 2104,
            "total_loss": 0.4889358878135681,
            "curr_kl_coeff": 0.10000000149011612,
            "weights_seq_no": 1.0,
            "curr_entropy_coeff": 0.01,
            "use_intrinsic_rewards": 0.0,
            "vf_explained_var": -0.0002334117889404297,
            "entropy": 0.6919407844543457,
            "num_module_steps_trained": 2104,
            "policy_loss": -1.3045934110778035e-06,
            "mean_kl_loss": 3.601740683478738e-09,
            "module_train_batch_size_mean": 185.69310182934865,
            "vf_loss": 0.9917132258415222,
            "vf_loss_unclipped": 108.53077697753906,
            "num_module_steps_trained_lifetime_throughput": 44.49969847943174
        },
        "differentiable_learners": {
            "intrinsic_attention_ppo_learner": {
                "__all_modules__": {
                    "num_env_steps_trained_lifetime": 537724,
                    "num_env_steps_trained": 537724,
                    "num_module_steps_trained_lifetime": 46288,
                    "num_module_steps_trained": 46288,
                    "num_env_steps_trained_lifetime_throughput": 32445.696932486615
                },
                "default_policy": {
                    "num_module_steps_trained": 23144,
                    "num_module_steps_trained_lifetime": 23144,
                    "mean_kl_loss": 6.151672504728367e-09,
                    "weights_seq_no": 11.0,
                    "use_intrinsic_rewards": 1.0,
                    "vf_loss": 0.9880346059799194,
                    "vf_explained_var": 1.7881393432617188e-07,
                    "entropy": 0.6919409036636353,
                    "policy_loss": 2.1191203813941684e-06,
                    "module_train_batch_size_mean": 189.35634598573975,
                    "vf_loss_unclipped": 79.18762969970703,
                    "diff_num_grad_updates_vs_sampler_policy": 11.0,
                    "total_loss": 0.4871000349521637
                },
                "intrinsic_reward_module": {
                    "diff_num_grad_updates_vs_sampler_policy": 11.0,
                    "num_module_steps_trained_lifetime": 23144,
                    "total_loss": 0.0,
                    "weights_seq_no": 11.0,
                    "num_module_steps_trained": 23144,
                    "module_train_batch_size_mean": 189.44131099408588
                }
            }
        },
        "intrinsic_reward_module": {
            "diff_num_grad_updates_vs_sampler_policy": 1.0,
            "num_trainable_parameters": 4499,
            "total_loss": 0.0,
            "weights_seq_no": 1.0,
            "num_module_steps_trained": 2104,
            "num_module_steps_trained_lifetime": 2104,
            "default_optimizer_learning_rate": 0.0005,
            "gradients_default_optimizer_global_norm": 0.0,
            "module_train_batch_size_mean": 185.65561593021275,
            "curr_entropy_coeff": 0.01,
            "num_module_steps_trained_lifetime_throughput": 44.19247688594894
        },
        "__all_modules__": {
            "num_env_steps_trained": 48884,
            "num_env_steps_trained_lifetime": 48884,
            "num_module_steps_trained": 4208,
            "num_trainable_parameters": 20502,
            "num_module_steps_trained_lifetime": 4208,
            "num_non_trainable_parameters": 0,
            "num_env_steps_trained_lifetime_throughput": 1128.691708066627,
            "num_module_steps_trained_throughput": 2253053.8582840646,
            "num_module_steps_trained_lifetime_throughput": 1241405.2853112966
        }
    },
    "num_training_step_calls_per_iteration": 1,
    "num_env_steps_sampled_lifetime": 21582.0,
    "evaluation": {
        "env_runners": {
            "episode_duration_sec_mean": 0.031305642799998167,
            "module_to_env_connector": {
                "timers": {
                    "connectors": {
                        "un_batch_to_individual_items": 2.477704492515582e-05,
                        "listify_data_for_vector_env": 4.2918877344223155e-05,
                        "tensor_to_numpy": 0.00014671942471019815,
                        "remove_single_ts_time_rank_from_batch": 4.165181668993841e-05,
                        "normalize_and_clip_actions": 7.789407506821664e-05,
                        "get_actions": 0.0004303768737631095
                    }
                },
                "connector_pipeline_timer": 0.0008718944527465365
            },
            "env_to_module_sum_episodes_length_out": 12.113619774867233,
            "env_to_module_connector": {
                "connector_pipeline_timer": 0.0003186925067279435,
                "timers": {
                    "connectors": {
                        "batch_individual_items": 4.988518890237982e-05,
                        "numpy_to_tensor": 0.00011390000029977983,
                        "add_states_from_episodes_to_batch": 8.902763403111273e-06,
                        "add_observations_from_episodes_to_batch": 1.1265149053328985e-05,
                        "add_time_dim_to_batch_and_zero_pad": 2.9585767319631783e-05
                    }
                }
            },
            "env_step_timer": 0.00011729117411616849,
            "sample": 0.16762584399839398,
            "episode_len_mean": 26.8,
            "episode_return_min": 15.0,
            "episode_return_mean": 26.8,
            "num_module_steps_sampled": {
                "default_policy": 134
            },
            "num_episodes_lifetime": 5,
            "episode_len_max": 39,
            "episode_len_min": 15,
            "num_env_steps_sampled_lifetime": 1142,
            "num_agent_steps_sampled": {
                "default_agent": 134
            },
            "num_module_steps_sampled_lifetime": {
                "default_policy": 134
            },
            "num_episodes": 5,
            "agent_episode_returns_mean": {
                "default_agent": 26.8
            },
            "env_reset_timer": 0.000333215000864584,
            "num_agent_steps_sampled_lifetime": {
                "default_agent": 134
            },
            "num_env_steps_sampled": 134,
            "env_to_module_sum_episodes_length_in": 12.113619774867233,
            "episode_return_max": 39.0,
            "weights_seq_no": 1.0,
            "module_episode_returns_mean": {
                "default_policy": 26.8
            },
            "rlmodule_inference_timer": 0.00030148610655536973
        },
        "num_healthy_workers": 1,
        "actor_manager_num_outstanding_async_reqs": 0,
        "num_remote_worker_restarts": 0
    },
    "fault_tolerance": {
        "num_healthy_workers": 0,
        "num_remote_worker_restarts": 0
    },
    "env_runner_group": {
        "actor_manager_num_outstanding_async_reqs": 0
    },
    "done": false,
    "training_iteration": 1,
    "trial_id": "5ce6b_00000",
    "date": "2025-08-11_00-58-09",
    "timestamp": 1754866689,
    "time_this_iter_s": 42.3406195640564,
    "time_total_s": 42.3406195640564,
    "pid": 28244,
    "hostname": "DESKTOP-LDQ7B16",
    "node_ip": "172.23.2.81",
    "config": {
        "exploration_config": {},
        "extra_python_environs_for_driver": {},
        "extra_python_environs_for_worker": {},
        "placement_strategy": "PACK",
        "num_gpus": 0,
        "_fake_gpus": false,
        "num_cpus_for_main_process": 6,
        "eager_tracing": true,
        "eager_max_retraces": 20,
        "tf_session_args": {
            "intra_op_parallelism_threads": 2,
            "inter_op_parallelism_threads": 2,
            "gpu_options": {
                "allow_growth": true
            },
            "log_device_placement": false,
            "device_count": {
                "CPU": 1
            },
            "allow_soft_placement": true
        },
        "local_tf_session_args": {
            "intra_op_parallelism_threads": 8,
            "inter_op_parallelism_threads": 8
        },
        "torch_compile_learner": false,
        "torch_compile_learner_what_to_compile": "forward_train",
        "torch_compile_learner_dynamo_backend": "inductor",
        "torch_compile_learner_dynamo_mode": null,
        "torch_compile_worker": false,
        "torch_compile_worker_dynamo_backend": "onnxrt",
        "torch_compile_worker_dynamo_mode": null,
        "torch_ddp_kwargs": {},
        "torch_skip_nan_gradients": false,
        "env": "CartPole-v1",
        "env_config": {},
        "observation_space": null,
        "action_space": null,
        "clip_rewards": null,
        "normalize_actions": true,
        "clip_actions": false,
        "_is_atari": null,
        "disable_env_checking": false,
        "render_env": false,
        "action_mask_key": "action_mask",
        "env_runner_cls": null,
        "num_env_runners": 0,
        "create_local_env_runner": true,
        "num_envs_per_env_runner": 1,
        "gym_env_vectorize_mode": "SYNC",
        "num_cpus_per_env_runner": 1,
        "num_gpus_per_env_runner": 0,
        "custom_resources_per_env_runner": {},
        "validate_env_runners_after_construction": true,
        "episodes_to_numpy": true,
        "max_requests_in_flight_per_env_runner": 1,
        "sample_timeout_s": 60.0,
        "_env_to_module_connector": null,
        "add_default_connectors_to_env_to_module_pipeline": true,
        "_module_to_env_connector": null,
        "add_default_connectors_to_module_to_env_pipeline": true,
        "merge_env_runner_states": "training_only",
        "broadcast_env_runner_states": true,
        "episode_lookback_horizon": 1,
        "rollout_fragment_length": "auto",
        "batch_mode": "complete_episodes",
        "compress_observations": false,
        "remote_worker_envs": false,
        "remote_env_batch_wait_ms": 0,
        "enable_tf1_exec_eagerly": false,
        "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>",
        "preprocessor_pref": "deepmind",
        "observation_filter": "NoFilter",
        "update_worker_filter_stats": true,
        "use_worker_filter_stats": true,
        "sampler_perf_stats_ema_coef": null,
        "_is_online": true,
        "num_learners": 0,
        "num_gpus_per_learner": 0,
        "num_cpus_per_learner": "auto",
        "num_aggregator_actors_per_learner": 0,
        "max_requests_in_flight_per_aggregator_actor": 3,
        "local_gpu_idx": 0,
        "max_requests_in_flight_per_learner": 3,
        "gamma": 0.99,
        "lr": 0.0005,
        "grad_clip": 0.5,
        "grad_clip_by": "global_norm",
        "_train_batch_size_per_learner": 1000,
        "train_batch_size": 4000,
        "num_epochs": 2,
        "minibatch_size": 200,
        "shuffle_batch_per_epoch": true,
        "model": {
            "fcnet_hiddens": [
                256,
                256
            ],
            "fcnet_activation": "tanh",
            "fcnet_weights_initializer": null,
            "fcnet_weights_initializer_config": null,
            "fcnet_bias_initializer": null,
            "fcnet_bias_initializer_config": null,
            "conv_filters": null,
            "conv_activation": "relu",
            "conv_kernel_initializer": null,
            "conv_kernel_initializer_config": null,
            "conv_bias_initializer": null,
            "conv_bias_initializer_config": null,
            "conv_transpose_kernel_initializer": null,
            "conv_transpose_kernel_initializer_config": null,
            "conv_transpose_bias_initializer": null,
            "conv_transpose_bias_initializer_config": null,
            "post_fcnet_hiddens": [],
            "post_fcnet_activation": "relu",
            "post_fcnet_weights_initializer": null,
            "post_fcnet_weights_initializer_config": null,
            "post_fcnet_bias_initializer": null,
            "post_fcnet_bias_initializer_config": null,
            "free_log_std": false,
            "log_std_clip_param": 20.0,
            "no_final_linear": false,
            "vf_share_layers": false,
            "use_lstm": false,
            "max_seq_len": 20,
            "lstm_cell_size": 256,
            "lstm_use_prev_action": false,
            "lstm_use_prev_reward": false,
            "lstm_weights_initializer": null,
            "lstm_weights_initializer_config": null,
            "lstm_bias_initializer": null,
            "lstm_bias_initializer_config": null,
            "_time_major": false,
            "use_attention": false,
            "attention_num_transformer_units": 1,
            "attention_dim": 64,
            "attention_num_heads": 1,
            "attention_head_dim": 32,
            "attention_memory_inference": 50,
            "attention_memory_training": 50,
            "attention_position_wise_mlp_dim": 32,
            "attention_init_gru_gate_bias": 2.0,
            "attention_use_n_prev_actions": 0,
            "attention_use_n_prev_rewards": 0,
            "framestack": true,
            "dim": 84,
            "grayscale": false,
            "zero_mean": true,
            "custom_model": null,
            "custom_model_config": {},
            "custom_action_dist": null,
            "custom_preprocessor": null,
            "encoder_latent_dim": null,
            "always_check_shapes": false,
            "lstm_use_prev_action_reward": -1,
            "_use_default_native_models": -1,
            "_disable_preprocessor_api": false,
            "_disable_action_flattening": false
        },
        "_learner_connector": null,
        "add_default_connectors_to_learner_pipeline": true,
        "learner_config_dict": {
            "intrinsic_reward_coeff": 0.01
        },
        "optimizer": {},
        "_learner_class": "<class 'source.intrinsic_attention_ppo.learners.IntrinsicAttentionMetaLearner.IntrinsicAttentionMetaLearner'>",
        "callbacks_on_algorithm_init": null,
        "callbacks_on_env_runners_recreated": null,
        "callbacks_on_offline_eval_runners_recreated": null,
        "callbacks_on_checkpoint_loaded": null,
        "callbacks_on_environment_created": null,
        "callbacks_on_episode_created": null,
        "callbacks_on_episode_start": null,
        "callbacks_on_episode_step": null,
        "callbacks_on_episode_end": null,
        "callbacks_on_evaluate_start": null,
        "callbacks_on_evaluate_end": null,
        "callbacks_on_evaluate_offline_start": null,
        "callbacks_on_evaluate_offline_end": null,
        "callbacks_on_sample_end": null,
        "callbacks_on_train_result": null,
        "explore": true,
        "enable_rl_module_and_learner": true,
        "enable_env_runner_and_connector_v2": true,
        "_prior_exploration_config": {
            "type": "StochasticSampling"
        },
        "count_steps_by": "env_steps",
        "policy_map_capacity": 100,
        "policy_mapping_fn": "<function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7553da886ac0>",
        "policies_to_train": null,
        "policy_states_are_swappable": false,
        "observation_fn": null,
        "offline_data_class": null,
        "input_read_method": "read_parquet",
        "input_read_method_kwargs": {},
        "input_read_schema": {},
        "input_read_episodes": false,
        "input_read_sample_batches": false,
        "input_read_batch_size": null,
        "input_filesystem": null,
        "input_filesystem_kwargs": {},
        "input_compress_columns": [
            "obs",
            "new_obs"
        ],
        "input_spaces_jsonable": true,
        "materialize_data": false,
        "materialize_mapped_data": true,
        "map_batches_kwargs": {},
        "iter_batches_kwargs": {},
        "ignore_final_observation": false,
        "prelearner_class": null,
        "prelearner_buffer_class": null,
        "prelearner_buffer_kwargs": {},
        "prelearner_module_synch_period": 10,
        "dataset_num_iters_per_learner": null,
        "input_config": {},
        "actions_in_input_normalized": false,
        "postprocess_inputs": false,
        "shuffle_buffer_size": 0,
        "output": null,
        "output_config": {},
        "output_compress_columns": [
            "obs",
            "new_obs"
        ],
        "output_max_file_size": 67108864,
        "output_max_rows_per_file": null,
        "output_write_remaining_data": false,
        "output_write_method": "write_parquet",
        "output_write_method_kwargs": {},
        "output_filesystem": null,
        "output_filesystem_kwargs": {},
        "output_write_episodes": true,
        "offline_sampling": false,
        "evaluation_interval": 1,
        "evaluation_duration": 5,
        "evaluation_duration_unit": "episodes",
        "evaluation_sample_timeout_s": 120.0,
        "evaluation_auto_duration_min_env_steps_per_sample": 100,
        "evaluation_auto_duration_max_env_steps_per_sample": 2000,
        "evaluation_parallel_to_training": false,
        "evaluation_force_reset_envs_before_iteration": true,
        "evaluation_config": null,
        "off_policy_estimation_methods": {},
        "ope_split_batch_by_episode": true,
        "evaluation_num_env_runners": 1,
        "in_evaluation": false,
        "sync_filters_on_rollout_workers_timeout_s": 10.0,
        "offline_evaluation_interval": null,
        "num_offline_eval_runners": 0,
        "offline_loss_for_module_fn": null,
        "offline_evaluation_duration": 1,
        "offline_evaluation_parallel_to_training": false,
        "offline_evaluation_timeout_s": 120.0,
        "num_cpus_per_offline_eval_runner": 1,
        "num_gpus_per_offline_eval_runner": 0,
        "custom_resources_per_offline_eval_runner": {},
        "restart_failed_offline_eval_runners": true,
        "ignore_offline_eval_runner_failures": false,
        "max_num_offline_eval_runner_restarts": 1000,
        "offline_eval_runner_restore_timeout_s": 1800.0,
        "max_requests_in_flight_per_offline_eval_runner": 1,
        "validate_offline_eval_runners_after_construction": true,
        "offline_eval_runner_health_probe_timeout_s": 30.0,
        "offline_eval_rl_module_inference_only": false,
        "broadcast_offline_eval_runner_states": false,
        "offline_eval_batch_size_per_runner": 256,
        "dataset_num_iters_per_eval_runner": 1,
        "keep_per_episode_custom_metrics": false,
        "metrics_episode_collection_timeout_s": 60.0,
        "metrics_num_episodes_for_smoothing": 100,
        "min_time_s_per_iteration": null,
        "min_train_timesteps_per_iteration": 0,
        "min_sample_timesteps_per_iteration": 0,
        "log_gradients": false,
        "export_native_model_files": false,
        "checkpoint_trainable_policies_only": false,
        "logger_creator": null,
        "logger_config": null,
        "log_level": "WARN",
        "log_sys_usage": true,
        "fake_sampler": false,
        "seed": 42,
        "restart_failed_env_runners": true,
        "ignore_env_runner_failures": false,
        "max_num_env_runner_restarts": 1000,
        "delay_between_env_runner_restarts_s": 60.0,
        "restart_failed_sub_environments": false,
        "num_consecutive_env_runner_failures_tolerance": 100,
        "env_runner_health_probe_timeout_s": 30.0,
        "env_runner_restore_timeout_s": 1800.0,
        "_model_config": {},
        "_rl_module_spec": "MultiRLModuleSpec(multi_rl_module_class=<class 'ray.rllib.core.rl_module.multi_rl_module.MultiRLModule'>, observation_space=None, action_space=None, inference_only=False, model_config=None, rl_module_specs={'default_policy': RLModuleSpec(module_class=<class 'source.intrinsic_attention_ppo.rl_modules.DifferentiablePPOModule.DifferentiablePPOModule'>, observation_space=None, action_space=None, inference_only=False, learner_only=False, model_config={'vf_share_layers': True, 'embedding_dim': 32, 'max_seq_len': 101, 'policy_head_hidden_sizes': [32, 64, 32], 'value_head_hidden_sizes': [32, 64, 32], 'embedding_hidden_sizes': [32, 64, 32]}, catalog_class=None, load_state_path=None, model_config_dict=None), 'intrinsic_reward_module': RLModuleSpec(module_class=<class 'source.intrinsic_attention_ppo.rl_modules.IntrinsicAttentionModule.IntrinsicAttentionModule'>, observation_space=None, action_space=None, inference_only=False, learner_only=True, model_config={'intrinsic_reward_network': {'encoder_hidden_sizes': [], 'encoding_dim': 1, 'num_heads': 1, 'head_hidden_sizes': None, 'layers': [{'type': 'attention'}]}, 'extrinsic_value_hidden_layers': [32, 64, 32], 'vf_share_layers': True, 'max_seq_len': 101}, catalog_class=None, load_state_path=None, model_config_dict=None)}, load_state_path=None, modules_to_load=None, module_specs={'default_policy': RLModuleSpec(module_class=<class 'source.intrinsic_attention_ppo.rl_modules.DifferentiablePPOModule.DifferentiablePPOModule'>, observation_space=None, action_space=None, inference_only=False, learner_only=False, model_config={'vf_share_layers': True, 'embedding_dim': 32, 'max_seq_len': 101, 'policy_head_hidden_sizes': [32, 64, 32], 'value_head_hidden_sizes': [32, 64, 32], 'embedding_hidden_sizes': [32, 64, 32]}, catalog_class=None, load_state_path=None, model_config_dict=None), 'intrinsic_reward_module': RLModuleSpec(module_class=<class 'source.intrinsic_attention_ppo.rl_modules.IntrinsicAttentionModule.IntrinsicAttentionModule'>, observation_space=None, action_space=None, inference_only=False, learner_only=True, model_config={'intrinsic_reward_network': {'encoder_hidden_sizes': [], 'encoding_dim': 1, 'num_heads': 1, 'head_hidden_sizes': None, 'layers': [{'type': 'attention'}]}, 'extrinsic_value_hidden_layers': [32, 64, 32], 'vf_share_layers': True, 'max_seq_len': 101}, catalog_class=None, load_state_path=None, model_config_dict=None)})",
        "algorithm_config_overrides_per_module": {
            "intrinsic_reward_module": {
                "lr": 0.0005
            }
        },
        "_per_module_overrides": {},
        "_validate_config": true,
        "_use_msgpack_checkpoints": false,
        "_torch_grad_scaler_class": null,
        "_torch_lr_scheduler_classes": null,
        "_tf_policy_handles_more_than_one_loss": false,
        "_disable_preprocessor_api": false,
        "_disable_action_flattening": false,
        "_disable_initialize_loss_from_dummy_batch": false,
        "_dont_auto_sync_env_runner_states": false,
        "env_task_fn": -1,
        "enable_connectors": -1,
        "simple_optimizer": false,
        "policy_map_cache": -1,
        "worker_cls": -1,
        "synchronize_filters": -1,
        "enable_async_evaluation": -1,
        "custom_async_evaluation_function": -1,
        "_enable_rl_module_api": -1,
        "auto_wrap_old_gym_envs": -1,
        "always_attach_evaluation_results": -1,
        "replay_sequence_length": null,
        "_disable_execution_plan_api": -1,
        "use_critic": true,
        "use_gae": true,
        "use_kl_loss": true,
        "kl_coeff": 0.2,
        "kl_target": 0.01,
        "vf_loss_coeff": 0.5,
        "entropy_coeff": 0.01,
        "clip_param": 0.2,
        "vf_clip_param": 1.0,
        "entropy_coeff_schedule": null,
        "lr_schedule": null,
        "sgd_minibatch_size": -1,
        "vf_share_layers": -1,
        "differentiable_learner_configs": [
            "DifferentiableLearnerConfig(learner_class=<class 'source.intrinsic_attention_ppo.learners.IntrinsicAttentionPPOLearner.IntrinsicAttentionPPOLearner'>, learner_connector=None, add_default_connectors_to_learner_pipeline=True, is_multi_agent=False, policies_to_update=['default_policy'], lr=0.0003, num_total_minibatches=0, num_epochs=2, minibatch_size=200, shuffle_batch_per_epoch=True)"
        ],
        "__stdout_file__": null,
        "__stderr_file__": null,
        "lambda": 0.95,
        "input": "sampler",
        "policies": {
            "default_policy": [
                null,
                null,
                null,
                null
            ]
        },
        "callbacks": "<class 'ray.rllib.callbacks.callbacks.RLlibCallback'>",
        "create_env_on_driver": false,
        "custom_eval_function": null,
        "framework": "torch"
    },
    "time_since_restore": 42.3406195640564,
    "iterations_since_restore": 1,
    "perf": {
        "cpu_util_percent": 43.10983606557377,
        "ram_util_percent": 65.12622950819673
    }
}
{
    "timers": {
        "training_iteration": 42.29832119742357,
        "restore_env_runners": 3.909362094418611e-05,
        "training_step": 42.29794451950809,
        "env_runner_sampling_timer": 1.118306291432018,
        "learner_update_timer": 41.068574699598976,
        "synch_weights": 0.0031073274536902317,
        "restore_eval_env_runners": 2.518900146242231e-05,
        "evaluation_iteration": 0.18411606400331948,
        "synch_eval_env_connectors": 0.0009634699963498861,
        "synch_env_connectors": 1.0167001164518297e-05
    },
    "env_runners": {
        "env_to_module_connector": {
            "timers": {
                "connectors": {
                    "batch_individual_items": 3.625194414860894e-05,
                    "numpy_to_tensor": 5.6098809807957146e-05,
                    "add_states_from_episodes_to_batch": 6.85603819034788e-06,
                    "add_observations_from_episodes_to_batch": 7.515520609449929e-06,
                    "add_time_dim_to_batch_and_zero_pad": 2.1186656156728578e-05
                }
            },
            "connector_pipeline_timer": 0.00018249090721334744
        },
        "rlmodule_inference_timer": 0.00018143969669490599,
        "sample": 0.023565316662343586,
        "num_module_steps_sampled_lifetime": {
            "default_policy": -883.9999999999854
        },
        "module_episode_returns_mean": {
            "default_policy": 22.6011111111111
        },
        "time_between_sampling": 0.33492695675608153,
        "num_episodes_lifetime": 45.0,
        "num_env_steps_sampled": 1030.0,
        "num_agent_steps_sampled": {
            "default_agent": 1030.0
        },
        "episode_len_max": 58,
        "module_to_env_connector": {
            "timers": {
                "connectors": {
                    "remove_single_ts_time_rank_from_batch": 3.0449339568441724e-05,
                    "normalize_and_clip_actions": 2.307214343288186e-05,
                    "listify_data_for_vector_env": 3.094367428330511e-05,
                    "un_batch_to_individual_items": 1.8080857469892457e-05,
                    "get_actions": 0.00018438497412783577,
                    "tensor_to_numpy": 5.701525841318302e-05
                }
            },
            "connector_pipeline_timer": 0.00042109899800967177
        },
        "env_to_module_sum_episodes_length_in": 14.402499038762347,
        "num_agent_steps_sampled_lifetime": {
            "default_agent": -883.9999999999854
        },
        "env_to_module_sum_episodes_length_out": 14.402499038762347,
        "episode_return_max": 58.0,
        "episode_duration_sec_mean": 0.021948628244564238,
        "episode_len_min": 10,
        "episode_len_mean": 22.6011111111111,
        "agent_episode_returns_mean": {
            "default_agent": 22.6011111111111
        },
        "num_env_steps_sampled_lifetime": -883.9999999999854,
        "num_module_steps_sampled": {
            "default_policy": 1030.0
        },
        "weights_seq_no": 1.0,
        "episode_return_min": 10.0,
        "episode_return_mean": 22.6011111111111,
        "num_episodes": 45.0,
        "env_step_timer": 6.654727981567619e-05,
        "env_reset_timer": 0.0003579757109823721,
        "num_env_steps_sampled_lifetime_throughput": 850.9745305089987
    },
    "__all_modules__": {
        "learner_connector_sum_episodes_length_in": 1008.2199999999999,
        "learner_connector": {
            "connector_pipeline_timer": 0.08777935457510465,
            "timers": {
                "connectors": {
                    "add_one_ts_to_episodes_and_truncate": 0.0061164188055408885,
                    "add_observations_from_episodes_to_batch": 0.0006308116595027968,
                    "add_columns_from_episodes_to_train_batch": 0.0195391628692596,
                    "add_time_dim_to_batch_and_zero_pad": 0.0583585499223409,
                    "add_states_from_episodes_to_batch": 0.0013344847351254429,
                    "batch_individual_items": 0.0011970593297155575,
                    "numpy_to_tensor": 0.00018022527096036355
                }
            }
        },
        "learner_connector_sum_episodes_length_out": 1052.23
    },
    "learners": {
        "default_policy": {
            "diff_num_grad_updates_vs_sampler_policy": 1.0,
            "num_trainable_parameters": 16003,
            "num_module_steps_trained_lifetime": 4358,
            "total_loss": 0.4860434830188751,
            "curr_kl_coeff": 0.05000000074505806,
            "weights_seq_no": 2.0,
            "curr_entropy_coeff": 0.01,
            "use_intrinsic_rewards": 0.0,
            "vf_explained_var": 0.000902712345123291,
            "entropy": 0.6918507218360901,
            "num_module_steps_trained": 2254,
            "policy_loss": -0.00014416924386750907,
            "mean_kl_loss": 1.6479403939229087e-06,
            "module_train_batch_size_mean": 185.92262047175723,
            "vf_loss": 0.9862118363380432,
            "vf_loss_unclipped": 65.56997680664062,
            "num_module_steps_trained_lifetime_throughput": 44.38632814904871
        },
        "differentiable_learners": {
            "intrinsic_attention_ppo_learner": {
                "__all_modules__": {
                    "num_env_steps_trained_lifetime": 1192204,
                    "num_env_steps_trained": 654480,
                    "num_module_steps_trained_lifetime": 101309,
                    "num_module_steps_trained": 55021,
                    "num_env_steps_trained_lifetime_throughput": 32076.92756423172
                },
                "default_policy": {
                    "num_module_steps_trained": 27333,
                    "num_module_steps_trained_lifetime": 50477,
                    "mean_kl_loss": 1.6225588979068561e-06,
                    "weights_seq_no": 23.0,
                    "use_intrinsic_rewards": 1.0,
                    "vf_loss": 0.9910996556282043,
                    "vf_explained_var": 2.384185791015625e-07,
                    "entropy": 0.6918494701385498,
                    "policy_loss": -0.00014963591820560396,
                    "module_train_batch_size_mean": 189.80476146709205,
                    "vf_loss_unclipped": 115.03559875488281,
                    "diff_num_grad_updates_vs_sampler_policy": 22.0,
                    "total_loss": 0.48848196864128113
                },
                "intrinsic_reward_module": {
                    "diff_num_grad_updates_vs_sampler_policy": 22.0,
                    "num_module_steps_trained_lifetime": 50832,
                    "total_loss": 0.0,
                    "weights_seq_no": 23.0,
                    "num_module_steps_trained": 27688,
                    "module_train_batch_size_mean": 191.70215505623716
                }
            }
        },
        "intrinsic_reward_module": {
            "diff_num_grad_updates_vs_sampler_policy": 1.0,
            "num_trainable_parameters": 4499,
            "total_loss": 0.0,
            "weights_seq_no": 2.0,
            "num_module_steps_trained": 2298,
            "num_module_steps_trained_lifetime": 4402,
            "default_optimizer_learning_rate": 0.0005,
            "gradients_default_optimizer_global_norm": 0.0,
            "module_train_batch_size_mean": 186.3396267993339,
            "curr_entropy_coeff": 0.01,
            "num_module_steps_trained_lifetime_throughput": 44.10986127172867
        },
        "__all_modules__": {
            "num_env_steps_trained": 54540,
            "num_env_steps_trained_lifetime": 103424,
            "num_module_steps_trained": 4552,
            "num_trainable_parameters": 20502,
            "num_module_steps_trained_lifetime": 8760,
            "num_non_trainable_parameters": 0,
            "num_env_steps_trained_lifetime_throughput": 1124.8783374680168,
            "num_module_steps_trained_throughput": 2207639.216536401,
            "num_module_steps_trained_lifetime_throughput": 1231748.9748916924
        }
    },
    "num_training_step_calls_per_iteration": 1,
    "evaluation": {
        "env_runners": {
            "episode_duration_sec_mean": 0.02750216519998503,
            "module_to_env_connector": {
                "timers": {
                    "connectors": {
                        "un_batch_to_individual_items": 2.0528699638396148e-05,
                        "listify_data_for_vector_env": 3.5669531509241195e-05,
                        "tensor_to_numpy": 8.685378459131682e-05,
                        "remove_single_ts_time_rank_from_batch": 3.5134666923105804e-05,
                        "normalize_and_clip_actions": 3.997054727880737e-05,
                        "get_actions": 0.0002655736427631522
                    }
                },
                "connector_pipeline_timer": 0.0005730759470620174
            },
            "env_to_module_sum_episodes_length_out": 12.810090002382454,
            "env_to_module_connector": {
                "connector_pipeline_timer": 0.0002263457117880374,
                "timers": {
                    "connectors": {
                        "batch_individual_items": 4.077136945913375e-05,
                        "numpy_to_tensor": 7.358004597157641e-05,
                        "add_states_from_episodes_to_batch": 7.897627405756645e-06,
                        "add_observations_from_episodes_to_batch": 9.297371568723448e-06,
                        "add_time_dim_to_batch_and_zero_pad": 2.4182825458023322e-05
                    }
                }
            },
            "env_step_timer": 8.230766557894394e-05,
            "sample": 0.16724644012836506,
            "episode_len_mean": 25.2,
            "episode_return_min": 15.0,
            "episode_return_mean": 25.2,
            "num_module_steps_sampled": {
                "default_policy": 118
            },
            "num_episodes_lifetime": 10,
            "episode_len_max": 39,
            "episode_len_min": 15,
            "num_env_steps_sampled_lifetime": 2156,
            "num_agent_steps_sampled": {
                "default_agent": 118
            },
            "num_module_steps_sampled_lifetime": {
                "default_policy": 252
            },
            "num_episodes": 5,
            "agent_episode_returns_mean": {
                "default_agent": 25.2
            },
            "env_reset_timer": 0.00033176521079440134,
            "num_agent_steps_sampled_lifetime": {
                "default_agent": 252
            },
            "num_env_steps_sampled": 118,
            "env_to_module_sum_episodes_length_in": 12.810090002382454,
            "episode_return_max": 39.0,
            "weights_seq_no": 2.0,
            "module_episode_returns_mean": {
                "default_policy": 25.2
            },
            "rlmodule_inference_timer": 0.0002235743952688291,
            "time_between_sampling": 56.79162693500257
        },
        "num_healthy_workers": 1,
        "actor_manager_num_outstanding_async_reqs": 0,
        "num_remote_worker_restarts": 0
    },
    "num_env_steps_sampled_lifetime": -883.9999999999854,
    "fault_tolerance": {
        "num_healthy_workers": 0,
        "num_remote_worker_restarts": 0
    },
    "env_runner_group": {
        "actor_manager_num_outstanding_async_reqs": 0
    },
    "done": false,
    "training_iteration": 2,
    "trial_id": "5ce6b_00000",
    "date": "2025-08-11_00-59-06",
    "timestamp": 1754866746,
    "time_this_iter_s": 56.873432874679565,
    "time_total_s": 99.21405243873596,
    "pid": 28244,
    "hostname": "DESKTOP-LDQ7B16",
    "node_ip": "172.23.2.81",
    "config": {
        "exploration_config": {},
        "extra_python_environs_for_driver": {},
        "extra_python_environs_for_worker": {},
        "placement_strategy": "PACK",
        "num_gpus": 0,
        "_fake_gpus": false,
        "num_cpus_for_main_process": 6,
        "eager_tracing": true,
        "eager_max_retraces": 20,
        "tf_session_args": {
            "intra_op_parallelism_threads": 2,
            "inter_op_parallelism_threads": 2,
            "gpu_options": {
                "allow_growth": true
            },
            "log_device_placement": false,
            "device_count": {
                "CPU": 1
            },
            "allow_soft_placement": true
        },
        "local_tf_session_args": {
            "intra_op_parallelism_threads": 8,
            "inter_op_parallelism_threads": 8
        },
        "torch_compile_learner": false,
        "torch_compile_learner_what_to_compile": "forward_train",
        "torch_compile_learner_dynamo_backend": "inductor",
        "torch_compile_learner_dynamo_mode": null,
        "torch_compile_worker": false,
        "torch_compile_worker_dynamo_backend": "onnxrt",
        "torch_compile_worker_dynamo_mode": null,
        "torch_ddp_kwargs": {},
        "torch_skip_nan_gradients": false,
        "env": "CartPole-v1",
        "env_config": {},
        "observation_space": null,
        "action_space": null,
        "clip_rewards": null,
        "normalize_actions": true,
        "clip_actions": false,
        "_is_atari": null,
        "disable_env_checking": false,
        "render_env": false,
        "action_mask_key": "action_mask",
        "env_runner_cls": null,
        "num_env_runners": 0,
        "create_local_env_runner": true,
        "num_envs_per_env_runner": 1,
        "gym_env_vectorize_mode": "SYNC",
        "num_cpus_per_env_runner": 1,
        "num_gpus_per_env_runner": 0,
        "custom_resources_per_env_runner": {},
        "validate_env_runners_after_construction": true,
        "episodes_to_numpy": true,
        "max_requests_in_flight_per_env_runner": 1,
        "sample_timeout_s": 60.0,
        "_env_to_module_connector": null,
        "add_default_connectors_to_env_to_module_pipeline": true,
        "_module_to_env_connector": null,
        "add_default_connectors_to_module_to_env_pipeline": true,
        "merge_env_runner_states": "training_only",
        "broadcast_env_runner_states": true,
        "episode_lookback_horizon": 1,
        "rollout_fragment_length": "auto",
        "batch_mode": "complete_episodes",
        "compress_observations": false,
        "remote_worker_envs": false,
        "remote_env_batch_wait_ms": 0,
        "enable_tf1_exec_eagerly": false,
        "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>",
        "preprocessor_pref": "deepmind",
        "observation_filter": "NoFilter",
        "update_worker_filter_stats": true,
        "use_worker_filter_stats": true,
        "sampler_perf_stats_ema_coef": null,
        "_is_online": true,
        "num_learners": 0,
        "num_gpus_per_learner": 0,
        "num_cpus_per_learner": "auto",
        "num_aggregator_actors_per_learner": 0,
        "max_requests_in_flight_per_aggregator_actor": 3,
        "local_gpu_idx": 0,
        "max_requests_in_flight_per_learner": 3,
        "gamma": 0.99,
        "lr": 0.0005,
        "grad_clip": 0.5,
        "grad_clip_by": "global_norm",
        "_train_batch_size_per_learner": 1000,
        "train_batch_size": 4000,
        "num_epochs": 2,
        "minibatch_size": 200,
        "shuffle_batch_per_epoch": true,
        "model": {
            "fcnet_hiddens": [
                256,
                256
            ],
            "fcnet_activation": "tanh",
            "fcnet_weights_initializer": null,
            "fcnet_weights_initializer_config": null,
            "fcnet_bias_initializer": null,
            "fcnet_bias_initializer_config": null,
            "conv_filters": null,
            "conv_activation": "relu",
            "conv_kernel_initializer": null,
            "conv_kernel_initializer_config": null,
            "conv_bias_initializer": null,
            "conv_bias_initializer_config": null,
            "conv_transpose_kernel_initializer": null,
            "conv_transpose_kernel_initializer_config": null,
            "conv_transpose_bias_initializer": null,
            "conv_transpose_bias_initializer_config": null,
            "post_fcnet_hiddens": [],
            "post_fcnet_activation": "relu",
            "post_fcnet_weights_initializer": null,
            "post_fcnet_weights_initializer_config": null,
            "post_fcnet_bias_initializer": null,
            "post_fcnet_bias_initializer_config": null,
            "free_log_std": false,
            "log_std_clip_param": 20.0,
            "no_final_linear": false,
            "vf_share_layers": false,
            "use_lstm": false,
            "max_seq_len": 20,
            "lstm_cell_size": 256,
            "lstm_use_prev_action": false,
            "lstm_use_prev_reward": false,
            "lstm_weights_initializer": null,
            "lstm_weights_initializer_config": null,
            "lstm_bias_initializer": null,
            "lstm_bias_initializer_config": null,
            "_time_major": false,
            "use_attention": false,
            "attention_num_transformer_units": 1,
            "attention_dim": 64,
            "attention_num_heads": 1,
            "attention_head_dim": 32,
            "attention_memory_inference": 50,
            "attention_memory_training": 50,
            "attention_position_wise_mlp_dim": 32,
            "attention_init_gru_gate_bias": 2.0,
            "attention_use_n_prev_actions": 0,
            "attention_use_n_prev_rewards": 0,
            "framestack": true,
            "dim": 84,
            "grayscale": false,
            "zero_mean": true,
            "custom_model": null,
            "custom_model_config": {},
            "custom_action_dist": null,
            "custom_preprocessor": null,
            "encoder_latent_dim": null,
            "always_check_shapes": false,
            "lstm_use_prev_action_reward": -1,
            "_use_default_native_models": -1,
            "_disable_preprocessor_api": false,
            "_disable_action_flattening": false
        },
        "_learner_connector": null,
        "add_default_connectors_to_learner_pipeline": true,
        "learner_config_dict": {
            "intrinsic_reward_coeff": 0.01
        },
        "optimizer": {},
        "_learner_class": "<class 'source.intrinsic_attention_ppo.learners.IntrinsicAttentionMetaLearner.IntrinsicAttentionMetaLearner'>",
        "callbacks_on_algorithm_init": null,
        "callbacks_on_env_runners_recreated": null,
        "callbacks_on_offline_eval_runners_recreated": null,
        "callbacks_on_checkpoint_loaded": null,
        "callbacks_on_environment_created": null,
        "callbacks_on_episode_created": null,
        "callbacks_on_episode_start": null,
        "callbacks_on_episode_step": null,
        "callbacks_on_episode_end": null,
        "callbacks_on_evaluate_start": null,
        "callbacks_on_evaluate_end": null,
        "callbacks_on_evaluate_offline_start": null,
        "callbacks_on_evaluate_offline_end": null,
        "callbacks_on_sample_end": null,
        "callbacks_on_train_result": null,
        "explore": true,
        "enable_rl_module_and_learner": true,
        "enable_env_runner_and_connector_v2": true,
        "_prior_exploration_config": {
            "type": "StochasticSampling"
        },
        "count_steps_by": "env_steps",
        "policy_map_capacity": 100,
        "policy_mapping_fn": "<function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7553da886ac0>",
        "policies_to_train": null,
        "policy_states_are_swappable": false,
        "observation_fn": null,
        "offline_data_class": null,
        "input_read_method": "read_parquet",
        "input_read_method_kwargs": {},
        "input_read_schema": {},
        "input_read_episodes": false,
        "input_read_sample_batches": false,
        "input_read_batch_size": null,
        "input_filesystem": null,
        "input_filesystem_kwargs": {},
        "input_compress_columns": [
            "obs",
            "new_obs"
        ],
        "input_spaces_jsonable": true,
        "materialize_data": false,
        "materialize_mapped_data": true,
        "map_batches_kwargs": {},
        "iter_batches_kwargs": {},
        "ignore_final_observation": false,
        "prelearner_class": null,
        "prelearner_buffer_class": null,
        "prelearner_buffer_kwargs": {},
        "prelearner_module_synch_period": 10,
        "dataset_num_iters_per_learner": null,
        "input_config": {},
        "actions_in_input_normalized": false,
        "postprocess_inputs": false,
        "shuffle_buffer_size": 0,
        "output": null,
        "output_config": {},
        "output_compress_columns": [
            "obs",
            "new_obs"
        ],
        "output_max_file_size": 67108864,
        "output_max_rows_per_file": null,
        "output_write_remaining_data": false,
        "output_write_method": "write_parquet",
        "output_write_method_kwargs": {},
        "output_filesystem": null,
        "output_filesystem_kwargs": {},
        "output_write_episodes": true,
        "offline_sampling": false,
        "evaluation_interval": 1,
        "evaluation_duration": 5,
        "evaluation_duration_unit": "episodes",
        "evaluation_sample_timeout_s": 120.0,
        "evaluation_auto_duration_min_env_steps_per_sample": 100,
        "evaluation_auto_duration_max_env_steps_per_sample": 2000,
        "evaluation_parallel_to_training": false,
        "evaluation_force_reset_envs_before_iteration": true,
        "evaluation_config": null,
        "off_policy_estimation_methods": {},
        "ope_split_batch_by_episode": true,
        "evaluation_num_env_runners": 1,
        "in_evaluation": false,
        "sync_filters_on_rollout_workers_timeout_s": 10.0,
        "offline_evaluation_interval": null,
        "num_offline_eval_runners": 0,
        "offline_loss_for_module_fn": null,
        "offline_evaluation_duration": 1,
        "offline_evaluation_parallel_to_training": false,
        "offline_evaluation_timeout_s": 120.0,
        "num_cpus_per_offline_eval_runner": 1,
        "num_gpus_per_offline_eval_runner": 0,
        "custom_resources_per_offline_eval_runner": {},
        "restart_failed_offline_eval_runners": true,
        "ignore_offline_eval_runner_failures": false,
        "max_num_offline_eval_runner_restarts": 1000,
        "offline_eval_runner_restore_timeout_s": 1800.0,
        "max_requests_in_flight_per_offline_eval_runner": 1,
        "validate_offline_eval_runners_after_construction": true,
        "offline_eval_runner_health_probe_timeout_s": 30.0,
        "offline_eval_rl_module_inference_only": false,
        "broadcast_offline_eval_runner_states": false,
        "offline_eval_batch_size_per_runner": 256,
        "dataset_num_iters_per_eval_runner": 1,
        "keep_per_episode_custom_metrics": false,
        "metrics_episode_collection_timeout_s": 60.0,
        "metrics_num_episodes_for_smoothing": 100,
        "min_time_s_per_iteration": null,
        "min_train_timesteps_per_iteration": 0,
        "min_sample_timesteps_per_iteration": 0,
        "log_gradients": false,
        "export_native_model_files": false,
        "checkpoint_trainable_policies_only": false,
        "logger_creator": null,
        "logger_config": null,
        "log_level": "WARN",
        "log_sys_usage": true,
        "fake_sampler": false,
        "seed": 42,
        "restart_failed_env_runners": true,
        "ignore_env_runner_failures": false,
        "max_num_env_runner_restarts": 1000,
        "delay_between_env_runner_restarts_s": 60.0,
        "restart_failed_sub_environments": false,
        "num_consecutive_env_runner_failures_tolerance": 100,
        "env_runner_health_probe_timeout_s": 30.0,
        "env_runner_restore_timeout_s": 1800.0,
        "_model_config": {},
        "_rl_module_spec": "MultiRLModuleSpec(multi_rl_module_class=<class 'ray.rllib.core.rl_module.multi_rl_module.MultiRLModule'>, observation_space=None, action_space=None, inference_only=False, model_config=None, rl_module_specs={'default_policy': RLModuleSpec(module_class=<class 'source.intrinsic_attention_ppo.rl_modules.DifferentiablePPOModule.DifferentiablePPOModule'>, observation_space=None, action_space=None, inference_only=False, learner_only=False, model_config={'vf_share_layers': True, 'embedding_dim': 32, 'max_seq_len': 101, 'policy_head_hidden_sizes': [32, 64, 32], 'value_head_hidden_sizes': [32, 64, 32], 'embedding_hidden_sizes': [32, 64, 32]}, catalog_class=None, load_state_path=None, model_config_dict=None), 'intrinsic_reward_module': RLModuleSpec(module_class=<class 'source.intrinsic_attention_ppo.rl_modules.IntrinsicAttentionModule.IntrinsicAttentionModule'>, observation_space=None, action_space=None, inference_only=False, learner_only=True, model_config={'intrinsic_reward_network': {'encoder_hidden_sizes': [], 'encoding_dim': 1, 'num_heads': 1, 'head_hidden_sizes': None, 'layers': [{'type': 'attention'}]}, 'extrinsic_value_hidden_layers': [32, 64, 32], 'vf_share_layers': True, 'max_seq_len': 101}, catalog_class=None, load_state_path=None, model_config_dict=None)}, load_state_path=None, modules_to_load=None, module_specs={'default_policy': RLModuleSpec(module_class=<class 'source.intrinsic_attention_ppo.rl_modules.DifferentiablePPOModule.DifferentiablePPOModule'>, observation_space=None, action_space=None, inference_only=False, learner_only=False, model_config={'vf_share_layers': True, 'embedding_dim': 32, 'max_seq_len': 101, 'policy_head_hidden_sizes': [32, 64, 32], 'value_head_hidden_sizes': [32, 64, 32], 'embedding_hidden_sizes': [32, 64, 32]}, catalog_class=None, load_state_path=None, model_config_dict=None), 'intrinsic_reward_module': RLModuleSpec(module_class=<class 'source.intrinsic_attention_ppo.rl_modules.IntrinsicAttentionModule.IntrinsicAttentionModule'>, observation_space=None, action_space=None, inference_only=False, learner_only=True, model_config={'intrinsic_reward_network': {'encoder_hidden_sizes': [], 'encoding_dim': 1, 'num_heads': 1, 'head_hidden_sizes': None, 'layers': [{'type': 'attention'}]}, 'extrinsic_value_hidden_layers': [32, 64, 32], 'vf_share_layers': True, 'max_seq_len': 101}, catalog_class=None, load_state_path=None, model_config_dict=None)})",
        "algorithm_config_overrides_per_module": {
            "intrinsic_reward_module": {
                "lr": 0.0005
            }
        },
        "_per_module_overrides": {},
        "_validate_config": true,
        "_use_msgpack_checkpoints": false,
        "_torch_grad_scaler_class": null,
        "_torch_lr_scheduler_classes": null,
        "_tf_policy_handles_more_than_one_loss": false,
        "_disable_preprocessor_api": false,
        "_disable_action_flattening": false,
        "_disable_initialize_loss_from_dummy_batch": false,
        "_dont_auto_sync_env_runner_states": false,
        "env_task_fn": -1,
        "enable_connectors": -1,
        "simple_optimizer": false,
        "policy_map_cache": -1,
        "worker_cls": -1,
        "synchronize_filters": -1,
        "enable_async_evaluation": -1,
        "custom_async_evaluation_function": -1,
        "_enable_rl_module_api": -1,
        "auto_wrap_old_gym_envs": -1,
        "always_attach_evaluation_results": -1,
        "replay_sequence_length": null,
        "_disable_execution_plan_api": -1,
        "use_critic": true,
        "use_gae": true,
        "use_kl_loss": true,
        "kl_coeff": 0.2,
        "kl_target": 0.01,
        "vf_loss_coeff": 0.5,
        "entropy_coeff": 0.01,
        "clip_param": 0.2,
        "vf_clip_param": 1.0,
        "entropy_coeff_schedule": null,
        "lr_schedule": null,
        "sgd_minibatch_size": -1,
        "vf_share_layers": -1,
        "differentiable_learner_configs": [
            "DifferentiableLearnerConfig(learner_class=<class 'source.intrinsic_attention_ppo.learners.IntrinsicAttentionPPOLearner.IntrinsicAttentionPPOLearner'>, learner_connector=None, add_default_connectors_to_learner_pipeline=True, is_multi_agent=False, policies_to_update=['default_policy'], lr=0.0003, num_total_minibatches=0, num_epochs=2, minibatch_size=200, shuffle_batch_per_epoch=True)"
        ],
        "__stdout_file__": null,
        "__stderr_file__": null,
        "lambda": 0.95,
        "input": "sampler",
        "policies": {
            "default_policy": [
                null,
                null,
                null,
                null
            ]
        },
        "callbacks": "<class 'ray.rllib.callbacks.callbacks.RLlibCallback'>",
        "create_env_on_driver": false,
        "custom_eval_function": null,
        "framework": "torch"
    },
    "time_since_restore": 99.21405243873596,
    "iterations_since_restore": 2,
    "perf": {
        "cpu_util_percent": 43.17901234567902,
        "ram_util_percent": 65.6395061728395
    }
}
{
    "timers": {
        "training_iteration": 42.375093407479326,
        "restore_env_runners": 3.898171472610556e-05,
        "training_step": 42.37471391657302,
        "env_runner_sampling_timer": 1.1195700599176366,
        "learner_update_timer": 41.144033647582944,
        "synch_weights": 0.003107219849165267,
        "restore_eval_env_runners": 2.518387140298728e-05,
        "evaluation_iteration": 0.18369879535326616,
        "synch_eval_env_connectors": 0.0009612236663815566,
        "synch_env_connectors": 1.0161931131733583e-05
    },
    "env_runners": {
        "env_to_module_connector": {
            "timers": {
                "connectors": {
                    "batch_individual_items": 4.083728097144516e-05,
                    "numpy_to_tensor": 6.46823975935135e-05,
                    "add_states_from_episodes_to_batch": 7.509992152155691e-06,
                    "add_observations_from_episodes_to_batch": 8.698092918294368e-06,
                    "add_time_dim_to_batch_and_zero_pad": 2.4322741345556773e-05
                }
            },
            "connector_pipeline_timer": 0.0002066442633232629
        },
        "rlmodule_inference_timer": 0.0002035300904994768,
        "sample": 0.024002705551819423,
        "num_module_steps_sampled_lifetime": {
            "default_policy": -24500.0
        },
        "module_episode_returns_mean": {
            "default_policy": 21.575
        },
        "time_between_sampling": 0.6555987062826388,
        "num_episodes_lifetime": -1035.0,
        "num_env_steps_sampled": 1014.0,
        "num_agent_steps_sampled": {
            "default_agent": 1014.0
        },
        "episode_len_max": 58,
        "module_to_env_connector": {
            "timers": {
                "connectors": {
                    "remove_single_ts_time_rank_from_batch": 3.4396848852204606e-05,
                    "normalize_and_clip_actions": 2.6528780172612756e-05,
                    "listify_data_for_vector_env": 3.513581793595357e-05,
                    "un_batch_to_individual_items": 2.013165128825267e-05,
                    "get_actions": 0.0002145525650471331,
                    "tensor_to_numpy": 6.472448028819334e-05
                }
            },
            "connector_pipeline_timer": 0.0004811719590509895
        },
        "env_to_module_sum_episodes_length_in": 14.159001323803011,
        "num_agent_steps_sampled_lifetime": {
            "default_agent": -24500.0
        },
        "env_to_module_sum_episodes_length_out": 14.159001323803011,
        "episode_return_max": 58.0,
        "episode_duration_sec_mean": 0.02390962806701281,
        "episode_len_min": 8,
        "episode_len_mean": 21.575,
        "agent_episode_returns_mean": {
            "default_agent": 21.575
        },
        "num_env_steps_sampled_lifetime": -24500.0,
        "num_module_steps_sampled": {
            "default_policy": 1014.0
        },
        "weights_seq_no": 2.0,
        "episode_return_min": 8.0,
        "episode_return_mean": 21.575,
        "num_episodes": 48.0,
        "env_step_timer": 7.229561120008951e-05,
        "env_reset_timer": 0.00027815747820628063,
        "num_env_steps_sampled_lifetime_throughput": 846.5507019297203
    },
    "__all_modules__": {
        "learner_connector_sum_episodes_length_in": 1008.2777999999998,
        "learner_connector": {
            "connector_pipeline_timer": 0.08779644054933668,
            "timers": {
                "connectors": {
                    "add_one_ts_to_episodes_and_truncate": 0.006098559507544996,
                    "add_observations_from_episodes_to_batch": 0.0006284691828972426,
                    "add_columns_from_episodes_to_train_batch": 0.019525593190594374,
                    "add_time_dim_to_batch_and_zero_pad": 0.058405785943143565,
                    "add_states_from_episodes_to_batch": 0.001338147057800961,
                    "batch_individual_items": 0.0011973470464348795,
                    "numpy_to_tensor": 0.00018029614820043205
                }
            }
        },
        "learner_connector_sum_episodes_length_out": 1052.3276999999998
    },
    "learners": {
        "default_policy": {
            "diff_num_grad_updates_vs_sampler_policy": 1.0,
            "num_trainable_parameters": 16003,
            "num_module_steps_trained_lifetime": 6569,
            "total_loss": 0.4887363612651825,
            "curr_kl_coeff": 0.02500000037252903,
            "weights_seq_no": 3.0,
            "curr_entropy_coeff": 0.01,
            "use_intrinsic_rewards": 0.0,
            "vf_explained_var": 0.002770662307739258,
            "entropy": 0.6918108463287354,
            "num_module_steps_trained": 2211,
            "policy_loss": 8.16602841950953e-05,
            "mean_kl_loss": 2.9762679787381785e-07,
            "module_train_batch_size_mean": 187.51517261935044,
            "vf_loss": 0.9911456108093262,
            "vf_loss_unclipped": 106.71764373779297,
            "num_module_steps_trained_lifetime_throughput": 44.33281256863533
        },
        "differentiable_learners": {
            "intrinsic_attention_ppo_learner": {
                "__all_modules__": {
                    "num_env_steps_trained_lifetime": 1778812,
                    "num_env_steps_trained": 586608,
                    "num_module_steps_trained_lifetime": 149527,
                    "num_module_steps_trained": 48218,
                    "num_env_steps_trained_lifetime_throughput": 31530.06091384308
                },
                "default_policy": {
                    "num_module_steps_trained": 24140,
                    "num_module_steps_trained_lifetime": 74617,
                    "mean_kl_loss": 2.90991351903358e-07,
                    "weights_seq_no": 34.0,
                    "use_intrinsic_rewards": 1.0,
                    "vf_loss": 0.9893286228179932,
                    "vf_explained_var": 1.7881393432617188e-07,
                    "entropy": 0.6918092966079712,
                    "policy_loss": -5.333206718205474e-05,
                    "module_train_batch_size_mean": 196.86699096253557,
                    "vf_loss_unclipped": 93.53105163574219,
                    "diff_num_grad_updates_vs_sampler_policy": 32.0,
                    "total_loss": 0.4876929521560669
                },
                "intrinsic_reward_module": {
                    "diff_num_grad_updates_vs_sampler_policy": 32.0,
                    "num_module_steps_trained_lifetime": 74910,
                    "total_loss": 0.0,
                    "weights_seq_no": 34.0,
                    "num_module_steps_trained": 24078,
                    "module_train_batch_size_mean": 197.05140577981527
                }
            }
        },
        "intrinsic_reward_module": {
            "diff_num_grad_updates_vs_sampler_policy": 1.0,
            "num_trainable_parameters": 4499,
            "total_loss": 0.0,
            "weights_seq_no": 3.0,
            "num_module_steps_trained": 2205,
            "num_module_steps_trained_lifetime": 6607,
            "default_optimizer_learning_rate": 0.0005,
            "gradients_default_optimizer_global_norm": 0.0,
            "module_train_batch_size_mean": 187.82985918544176,
            "curr_entropy_coeff": 0.01,
            "num_module_steps_trained_lifetime_throughput": 44.07837068184539
        },
        "__all_modules__": {
            "num_env_steps_trained": 53328,
            "num_env_steps_trained_lifetime": 156752,
            "num_module_steps_trained": 4416,
            "num_trainable_parameters": 20502,
            "num_module_steps_trained_lifetime": 13176,
            "num_non_trainable_parameters": 0,
            "num_env_steps_trained_lifetime_throughput": 1121.7559849703393,
            "num_module_steps_trained_throughput": 2154649.3305818005,
            "num_module_steps_trained_lifetime_throughput": 1223687.5205298378
        }
    },
    "num_training_step_calls_per_iteration": 1,
    "evaluation": {
        "env_runners": {
            "episode_duration_sec_mean": 0.025354716866665208,
            "module_to_env_connector": {
                "timers": {
                    "connectors": {
                        "un_batch_to_individual_items": 2.116812007013107e-05,
                        "listify_data_for_vector_env": 3.3684524386501925e-05,
                        "tensor_to_numpy": 7.308112812745887e-05,
                        "remove_single_ts_time_rank_from_batch": 3.3595619032278724e-05,
                        "normalize_and_clip_actions": 2.9905351149624432e-05,
                        "get_actions": 0.00023452821096098356
                    }
                },
                "connector_pipeline_timer": 0.0005142936304786514
            },
            "env_to_module_sum_episodes_length_out": 12.242997783673523,
            "env_to_module_connector": {
                "connector_pipeline_timer": 0.0002084975226647365,
                "timers": {
                    "connectors": {
                        "batch_individual_items": 3.995909781153584e-05,
                        "numpy_to_tensor": 6.695700153936975e-05,
                        "add_states_from_episodes_to_batch": 7.783311337240493e-06,
                        "add_observations_from_episodes_to_batch": 8.707189664707349e-06,
                        "add_time_dim_to_batch_and_zero_pad": 2.3294506817567346e-05
                    }
                }
            },
            "env_step_timer": 7.456569209571886e-05,
            "sample": 0.1667017477271176,
            "episode_len_mean": 23.133333333333333,
            "episode_return_min": 10.0,
            "episode_return_mean": 23.133333333333333,
            "num_module_steps_sampled": {
                "default_policy": 95
            },
            "num_episodes_lifetime": 15,
            "episode_len_max": 39,
            "episode_len_min": 10,
            "num_env_steps_sampled_lifetime": 3147,
            "num_agent_steps_sampled": {
                "default_agent": 95
            },
            "num_module_steps_sampled_lifetime": {
                "default_policy": 347
            },
            "num_episodes": 5,
            "agent_episode_returns_mean": {
                "default_agent": 23.133333333333333
            },
            "env_reset_timer": 0.0003305954386909434,
            "num_agent_steps_sampled_lifetime": {
                "default_agent": 347
            },
            "num_env_steps_sampled": 95,
            "env_to_module_sum_episodes_length_in": 12.242997783673523,
            "episode_return_max": 39.0,
            "weights_seq_no": 3.0,
            "module_episode_returns_mean": {
                "default_policy": 23.133333333333333
            },
            "rlmodule_inference_timer": 0.0002089368025994062,
            "time_between_sampling": 56.724124362112555
        },
        "num_healthy_workers": 1,
        "actor_manager_num_outstanding_async_reqs": 0,
        "num_remote_worker_restarts": 0
    },
    "num_env_steps_sampled_lifetime": -24500.0,
    "fault_tolerance": {
        "num_healthy_workers": 0,
        "num_remote_worker_restarts": 0
    },
    "env_runner_group": {
        "actor_manager_num_outstanding_async_reqs": 0
    },
    "done": false,
    "training_iteration": 3,
    "trial_id": "5ce6b_00000",
    "date": "2025-08-11_00-59-56",
    "timestamp": 1754866796,
    "time_this_iter_s": 50.107303619384766,
    "time_total_s": 149.32135605812073,
    "pid": 28244,
    "hostname": "DESKTOP-LDQ7B16",
    "node_ip": "172.23.2.81",
    "config": {
        "exploration_config": {},
        "extra_python_environs_for_driver": {},
        "extra_python_environs_for_worker": {},
        "placement_strategy": "PACK",
        "num_gpus": 0,
        "_fake_gpus": false,
        "num_cpus_for_main_process": 6,
        "eager_tracing": true,
        "eager_max_retraces": 20,
        "tf_session_args": {
            "intra_op_parallelism_threads": 2,
            "inter_op_parallelism_threads": 2,
            "gpu_options": {
                "allow_growth": true
            },
            "log_device_placement": false,
            "device_count": {
                "CPU": 1
            },
            "allow_soft_placement": true
        },
        "local_tf_session_args": {
            "intra_op_parallelism_threads": 8,
            "inter_op_parallelism_threads": 8
        },
        "torch_compile_learner": false,
        "torch_compile_learner_what_to_compile": "forward_train",
        "torch_compile_learner_dynamo_backend": "inductor",
        "torch_compile_learner_dynamo_mode": null,
        "torch_compile_worker": false,
        "torch_compile_worker_dynamo_backend": "onnxrt",
        "torch_compile_worker_dynamo_mode": null,
        "torch_ddp_kwargs": {},
        "torch_skip_nan_gradients": false,
        "env": "CartPole-v1",
        "env_config": {},
        "observation_space": null,
        "action_space": null,
        "clip_rewards": null,
        "normalize_actions": true,
        "clip_actions": false,
        "_is_atari": null,
        "disable_env_checking": false,
        "render_env": false,
        "action_mask_key": "action_mask",
        "env_runner_cls": null,
        "num_env_runners": 0,
        "create_local_env_runner": true,
        "num_envs_per_env_runner": 1,
        "gym_env_vectorize_mode": "SYNC",
        "num_cpus_per_env_runner": 1,
        "num_gpus_per_env_runner": 0,
        "custom_resources_per_env_runner": {},
        "validate_env_runners_after_construction": true,
        "episodes_to_numpy": true,
        "max_requests_in_flight_per_env_runner": 1,
        "sample_timeout_s": 60.0,
        "_env_to_module_connector": null,
        "add_default_connectors_to_env_to_module_pipeline": true,
        "_module_to_env_connector": null,
        "add_default_connectors_to_module_to_env_pipeline": true,
        "merge_env_runner_states": "training_only",
        "broadcast_env_runner_states": true,
        "episode_lookback_horizon": 1,
        "rollout_fragment_length": "auto",
        "batch_mode": "complete_episodes",
        "compress_observations": false,
        "remote_worker_envs": false,
        "remote_env_batch_wait_ms": 0,
        "enable_tf1_exec_eagerly": false,
        "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>",
        "preprocessor_pref": "deepmind",
        "observation_filter": "NoFilter",
        "update_worker_filter_stats": true,
        "use_worker_filter_stats": true,
        "sampler_perf_stats_ema_coef": null,
        "_is_online": true,
        "num_learners": 0,
        "num_gpus_per_learner": 0,
        "num_cpus_per_learner": "auto",
        "num_aggregator_actors_per_learner": 0,
        "max_requests_in_flight_per_aggregator_actor": 3,
        "local_gpu_idx": 0,
        "max_requests_in_flight_per_learner": 3,
        "gamma": 0.99,
        "lr": 0.0005,
        "grad_clip": 0.5,
        "grad_clip_by": "global_norm",
        "_train_batch_size_per_learner": 1000,
        "train_batch_size": 4000,
        "num_epochs": 2,
        "minibatch_size": 200,
        "shuffle_batch_per_epoch": true,
        "model": {
            "fcnet_hiddens": [
                256,
                256
            ],
            "fcnet_activation": "tanh",
            "fcnet_weights_initializer": null,
            "fcnet_weights_initializer_config": null,
            "fcnet_bias_initializer": null,
            "fcnet_bias_initializer_config": null,
            "conv_filters": null,
            "conv_activation": "relu",
            "conv_kernel_initializer": null,
            "conv_kernel_initializer_config": null,
            "conv_bias_initializer": null,
            "conv_bias_initializer_config": null,
            "conv_transpose_kernel_initializer": null,
            "conv_transpose_kernel_initializer_config": null,
            "conv_transpose_bias_initializer": null,
            "conv_transpose_bias_initializer_config": null,
            "post_fcnet_hiddens": [],
            "post_fcnet_activation": "relu",
            "post_fcnet_weights_initializer": null,
            "post_fcnet_weights_initializer_config": null,
            "post_fcnet_bias_initializer": null,
            "post_fcnet_bias_initializer_config": null,
            "free_log_std": false,
            "log_std_clip_param": 20.0,
            "no_final_linear": false,
            "vf_share_layers": false,
            "use_lstm": false,
            "max_seq_len": 20,
            "lstm_cell_size": 256,
            "lstm_use_prev_action": false,
            "lstm_use_prev_reward": false,
            "lstm_weights_initializer": null,
            "lstm_weights_initializer_config": null,
            "lstm_bias_initializer": null,
            "lstm_bias_initializer_config": null,
            "_time_major": false,
            "use_attention": false,
            "attention_num_transformer_units": 1,
            "attention_dim": 64,
            "attention_num_heads": 1,
            "attention_head_dim": 32,
            "attention_memory_inference": 50,
            "attention_memory_training": 50,
            "attention_position_wise_mlp_dim": 32,
            "attention_init_gru_gate_bias": 2.0,
            "attention_use_n_prev_actions": 0,
            "attention_use_n_prev_rewards": 0,
            "framestack": true,
            "dim": 84,
            "grayscale": false,
            "zero_mean": true,
            "custom_model": null,
            "custom_model_config": {},
            "custom_action_dist": null,
            "custom_preprocessor": null,
            "encoder_latent_dim": null,
            "always_check_shapes": false,
            "lstm_use_prev_action_reward": -1,
            "_use_default_native_models": -1,
            "_disable_preprocessor_api": false,
            "_disable_action_flattening": false
        },
        "_learner_connector": null,
        "add_default_connectors_to_learner_pipeline": true,
        "learner_config_dict": {
            "intrinsic_reward_coeff": 0.01
        },
        "optimizer": {},
        "_learner_class": "<class 'source.intrinsic_attention_ppo.learners.IntrinsicAttentionMetaLearner.IntrinsicAttentionMetaLearner'>",
        "callbacks_on_algorithm_init": null,
        "callbacks_on_env_runners_recreated": null,
        "callbacks_on_offline_eval_runners_recreated": null,
        "callbacks_on_checkpoint_loaded": null,
        "callbacks_on_environment_created": null,
        "callbacks_on_episode_created": null,
        "callbacks_on_episode_start": null,
        "callbacks_on_episode_step": null,
        "callbacks_on_episode_end": null,
        "callbacks_on_evaluate_start": null,
        "callbacks_on_evaluate_end": null,
        "callbacks_on_evaluate_offline_start": null,
        "callbacks_on_evaluate_offline_end": null,
        "callbacks_on_sample_end": null,
        "callbacks_on_train_result": null,
        "explore": true,
        "enable_rl_module_and_learner": true,
        "enable_env_runner_and_connector_v2": true,
        "_prior_exploration_config": {
            "type": "StochasticSampling"
        },
        "count_steps_by": "env_steps",
        "policy_map_capacity": 100,
        "policy_mapping_fn": "<function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7553da886ac0>",
        "policies_to_train": null,
        "policy_states_are_swappable": false,
        "observation_fn": null,
        "offline_data_class": null,
        "input_read_method": "read_parquet",
        "input_read_method_kwargs": {},
        "input_read_schema": {},
        "input_read_episodes": false,
        "input_read_sample_batches": false,
        "input_read_batch_size": null,
        "input_filesystem": null,
        "input_filesystem_kwargs": {},
        "input_compress_columns": [
            "obs",
            "new_obs"
        ],
        "input_spaces_jsonable": true,
        "materialize_data": false,
        "materialize_mapped_data": true,
        "map_batches_kwargs": {},
        "iter_batches_kwargs": {},
        "ignore_final_observation": false,
        "prelearner_class": null,
        "prelearner_buffer_class": null,
        "prelearner_buffer_kwargs": {},
        "prelearner_module_synch_period": 10,
        "dataset_num_iters_per_learner": null,
        "input_config": {},
        "actions_in_input_normalized": false,
        "postprocess_inputs": false,
        "shuffle_buffer_size": 0,
        "output": null,
        "output_config": {},
        "output_compress_columns": [
            "obs",
            "new_obs"
        ],
        "output_max_file_size": 67108864,
        "output_max_rows_per_file": null,
        "output_write_remaining_data": false,
        "output_write_method": "write_parquet",
        "output_write_method_kwargs": {},
        "output_filesystem": null,
        "output_filesystem_kwargs": {},
        "output_write_episodes": true,
        "offline_sampling": false,
        "evaluation_interval": 1,
        "evaluation_duration": 5,
        "evaluation_duration_unit": "episodes",
        "evaluation_sample_timeout_s": 120.0,
        "evaluation_auto_duration_min_env_steps_per_sample": 100,
        "evaluation_auto_duration_max_env_steps_per_sample": 2000,
        "evaluation_parallel_to_training": false,
        "evaluation_force_reset_envs_before_iteration": true,
        "evaluation_config": null,
        "off_policy_estimation_methods": {},
        "ope_split_batch_by_episode": true,
        "evaluation_num_env_runners": 1,
        "in_evaluation": false,
        "sync_filters_on_rollout_workers_timeout_s": 10.0,
        "offline_evaluation_interval": null,
        "num_offline_eval_runners": 0,
        "offline_loss_for_module_fn": null,
        "offline_evaluation_duration": 1,
        "offline_evaluation_parallel_to_training": false,
        "offline_evaluation_timeout_s": 120.0,
        "num_cpus_per_offline_eval_runner": 1,
        "num_gpus_per_offline_eval_runner": 0,
        "custom_resources_per_offline_eval_runner": {},
        "restart_failed_offline_eval_runners": true,
        "ignore_offline_eval_runner_failures": false,
        "max_num_offline_eval_runner_restarts": 1000,
        "offline_eval_runner_restore_timeout_s": 1800.0,
        "max_requests_in_flight_per_offline_eval_runner": 1,
        "validate_offline_eval_runners_after_construction": true,
        "offline_eval_runner_health_probe_timeout_s": 30.0,
        "offline_eval_rl_module_inference_only": false,
        "broadcast_offline_eval_runner_states": false,
        "offline_eval_batch_size_per_runner": 256,
        "dataset_num_iters_per_eval_runner": 1,
        "keep_per_episode_custom_metrics": false,
        "metrics_episode_collection_timeout_s": 60.0,
        "metrics_num_episodes_for_smoothing": 100,
        "min_time_s_per_iteration": null,
        "min_train_timesteps_per_iteration": 0,
        "min_sample_timesteps_per_iteration": 0,
        "log_gradients": false,
        "export_native_model_files": false,
        "checkpoint_trainable_policies_only": false,
        "logger_creator": null,
        "logger_config": null,
        "log_level": "WARN",
        "log_sys_usage": true,
        "fake_sampler": false,
        "seed": 42,
        "restart_failed_env_runners": true,
        "ignore_env_runner_failures": false,
        "max_num_env_runner_restarts": 1000,
        "delay_between_env_runner_restarts_s": 60.0,
        "restart_failed_sub_environments": false,
        "num_consecutive_env_runner_failures_tolerance": 100,
        "env_runner_health_probe_timeout_s": 30.0,
        "env_runner_restore_timeout_s": 1800.0,
        "_model_config": {},
        "_rl_module_spec": "MultiRLModuleSpec(multi_rl_module_class=<class 'ray.rllib.core.rl_module.multi_rl_module.MultiRLModule'>, observation_space=None, action_space=None, inference_only=False, model_config=None, rl_module_specs={'default_policy': RLModuleSpec(module_class=<class 'source.intrinsic_attention_ppo.rl_modules.DifferentiablePPOModule.DifferentiablePPOModule'>, observation_space=None, action_space=None, inference_only=False, learner_only=False, model_config={'vf_share_layers': True, 'embedding_dim': 32, 'max_seq_len': 101, 'policy_head_hidden_sizes': [32, 64, 32], 'value_head_hidden_sizes': [32, 64, 32], 'embedding_hidden_sizes': [32, 64, 32]}, catalog_class=None, load_state_path=None, model_config_dict=None), 'intrinsic_reward_module': RLModuleSpec(module_class=<class 'source.intrinsic_attention_ppo.rl_modules.IntrinsicAttentionModule.IntrinsicAttentionModule'>, observation_space=None, action_space=None, inference_only=False, learner_only=True, model_config={'intrinsic_reward_network': {'encoder_hidden_sizes': [], 'encoding_dim': 1, 'num_heads': 1, 'head_hidden_sizes': None, 'layers': [{'type': 'attention'}]}, 'extrinsic_value_hidden_layers': [32, 64, 32], 'vf_share_layers': True, 'max_seq_len': 101}, catalog_class=None, load_state_path=None, model_config_dict=None)}, load_state_path=None, modules_to_load=None, module_specs={'default_policy': RLModuleSpec(module_class=<class 'source.intrinsic_attention_ppo.rl_modules.DifferentiablePPOModule.DifferentiablePPOModule'>, observation_space=None, action_space=None, inference_only=False, learner_only=False, model_config={'vf_share_layers': True, 'embedding_dim': 32, 'max_seq_len': 101, 'policy_head_hidden_sizes': [32, 64, 32], 'value_head_hidden_sizes': [32, 64, 32], 'embedding_hidden_sizes': [32, 64, 32]}, catalog_class=None, load_state_path=None, model_config_dict=None), 'intrinsic_reward_module': RLModuleSpec(module_class=<class 'source.intrinsic_attention_ppo.rl_modules.IntrinsicAttentionModule.IntrinsicAttentionModule'>, observation_space=None, action_space=None, inference_only=False, learner_only=True, model_config={'intrinsic_reward_network': {'encoder_hidden_sizes': [], 'encoding_dim': 1, 'num_heads': 1, 'head_hidden_sizes': None, 'layers': [{'type': 'attention'}]}, 'extrinsic_value_hidden_layers': [32, 64, 32], 'vf_share_layers': True, 'max_seq_len': 101}, catalog_class=None, load_state_path=None, model_config_dict=None)})",
        "algorithm_config_overrides_per_module": {
            "intrinsic_reward_module": {
                "lr": 0.0005
            }
        },
        "_per_module_overrides": {},
        "_validate_config": true,
        "_use_msgpack_checkpoints": false,
        "_torch_grad_scaler_class": null,
        "_torch_lr_scheduler_classes": null,
        "_tf_policy_handles_more_than_one_loss": false,
        "_disable_preprocessor_api": false,
        "_disable_action_flattening": false,
        "_disable_initialize_loss_from_dummy_batch": false,
        "_dont_auto_sync_env_runner_states": false,
        "env_task_fn": -1,
        "enable_connectors": -1,
        "simple_optimizer": false,
        "policy_map_cache": -1,
        "worker_cls": -1,
        "synchronize_filters": -1,
        "enable_async_evaluation": -1,
        "custom_async_evaluation_function": -1,
        "_enable_rl_module_api": -1,
        "auto_wrap_old_gym_envs": -1,
        "always_attach_evaluation_results": -1,
        "replay_sequence_length": null,
        "_disable_execution_plan_api": -1,
        "use_critic": true,
        "use_gae": true,
        "use_kl_loss": true,
        "kl_coeff": 0.2,
        "kl_target": 0.01,
        "vf_loss_coeff": 0.5,
        "entropy_coeff": 0.01,
        "clip_param": 0.2,
        "vf_clip_param": 1.0,
        "entropy_coeff_schedule": null,
        "lr_schedule": null,
        "sgd_minibatch_size": -1,
        "vf_share_layers": -1,
        "differentiable_learner_configs": [
            "DifferentiableLearnerConfig(learner_class=<class 'source.intrinsic_attention_ppo.learners.IntrinsicAttentionPPOLearner.IntrinsicAttentionPPOLearner'>, learner_connector=None, add_default_connectors_to_learner_pipeline=True, is_multi_agent=False, policies_to_update=['default_policy'], lr=0.0003, num_total_minibatches=0, num_epochs=2, minibatch_size=200, shuffle_batch_per_epoch=True)"
        ],
        "__stdout_file__": null,
        "__stderr_file__": null,
        "lambda": 0.95,
        "input": "sampler",
        "policies": {
            "default_policy": [
                null,
                null,
                null,
                null
            ]
        },
        "callbacks": "<class 'ray.rllib.callbacks.callbacks.RLlibCallback'>",
        "create_env_on_driver": false,
        "custom_eval_function": null,
        "framework": "torch"
    },
    "time_since_restore": 149.32135605812073,
    "iterations_since_restore": 3,
    "perf": {
        "cpu_util_percent": 42.49166666666666,
        "ram_util_percent": 65.89305555555556
    }
}
{
    "timers": {
        "training_iteration": 42.522303295034526,
        "restore_env_runners": 3.873902762814396e-05,
        "training_step": 42.52192197445728,
        "env_runner_sampling_timer": 1.12361363674847,
        "learner_update_timer": 41.28716354599717,
        "synch_weights": 0.0031101739006694183,
        "restore_eval_env_runners": 2.512076266211807e-05,
        "evaluation_iteration": 0.18313258066974086,
        "synch_eval_env_connectors": 0.0009616801997064612,
        "synch_env_connectors": 1.0157981801603456e-05
    },
    "env_runners": {
        "env_to_module_connector": {
            "timers": {
                "connectors": {
                    "batch_individual_items": 4.5562681440529637e-05,
                    "numpy_to_tensor": 7.83739554038551e-05,
                    "add_states_from_episodes_to_batch": 8.912640207944008e-06,
                    "add_observations_from_episodes_to_batch": 1.0468847012920596e-05,
                    "add_time_dim_to_batch_and_zero_pad": 2.936164751615732e-05
                }
            },
            "connector_pipeline_timer": 0.00024363617319596908
        },
        "rlmodule_inference_timer": 0.0002631073691097712,
        "sample": 0.02572966992118131,
        "num_module_steps_sampled_lifetime": {
            "default_policy": -47092.000000000044
        },
        "module_episode_returns_mean": {
            "default_policy": 21.536382978723406
        },
        "time_between_sampling": 0.7989388177472821,
        "num_episodes_lifetime": -2069.0,
        "num_env_steps_sampled": 1015.0000000000002,
        "num_agent_steps_sampled": {
            "default_agent": 1015.0000000000002
        },
        "episode_len_max": 61,
        "module_to_env_connector": {
            "timers": {
                "connectors": {
                    "remove_single_ts_time_rank_from_batch": 3.872810226603651e-05,
                    "normalize_and_clip_actions": 3.187783030873755e-05,
                    "listify_data_for_vector_env": 4.116018214041746e-05,
                    "un_batch_to_individual_items": 2.361861896385176e-05,
                    "get_actions": 0.00029315259969920645,
                    "tensor_to_numpy": 8.798865899817009e-05
                }
            },
            "connector_pipeline_timer": 0.0006164834678204532
        },
        "env_to_module_sum_episodes_length_in": 14.142158166729626,
        "num_agent_steps_sampled_lifetime": {
            "default_agent": -47092.000000000044
        },
        "env_to_module_sum_episodes_length_out": 14.142158166729626,
        "episode_return_max": 61.0,
        "episode_duration_sec_mean": 0.029337731106069007,
        "episode_len_min": 8,
        "episode_len_mean": 21.536382978723406,
        "agent_episode_returns_mean": {
            "default_agent": 21.536382978723406
        },
        "num_env_steps_sampled_lifetime": -47092.000000000044,
        "num_module_steps_sampled": {
            "default_policy": 1015.0000000000002
        },
        "weights_seq_no": 3.0,
        "episode_return_min": 8.0,
        "episode_return_mean": 21.536382978723406,
        "num_episodes": 47.0,
        "env_step_timer": 8.671706820784638e-05,
        "env_reset_timer": 0.0002703521257036756,
        "num_env_steps_sampled_lifetime_throughput": 738.7723484389254
    },
    "__all_modules__": {
        "learner_connector_sum_episodes_length_in": 1008.3450219999999,
        "learner_connector": {
            "connector_pipeline_timer": 0.08780324443382286,
            "timers": {
                "connectors": {
                    "add_one_ts_to_episodes_and_truncate": 0.006073638042505357,
                    "add_observations_from_episodes_to_batch": 0.0006254709910640085,
                    "add_columns_from_episodes_to_train_batch": 0.019515646848703525,
                    "add_time_dim_to_batch_and_zero_pad": 0.058444880543741945,
                    "add_states_from_episodes_to_batch": 0.0013444464672185278,
                    "batch_individual_items": 0.0011973901259971318,
                    "numpy_to_tensor": 0.00018042277671675397
                }
            }
        },
        "learner_connector_sum_episodes_length_out": 1052.4244229999997
    },
    "learners": {
        "default_policy": {
            "diff_num_grad_updates_vs_sampler_policy": 1.0,
            "num_trainable_parameters": 16003,
            "num_module_steps_trained_lifetime": 8732,
            "total_loss": 0.48701000213623047,
            "curr_kl_coeff": 0.012500000186264515,
            "weights_seq_no": 4.0,
            "curr_entropy_coeff": 0.01,
            "use_intrinsic_rewards": 0.0,
            "vf_explained_var": 0.0009524822235107422,
            "entropy": 0.6918092370033264,
            "num_module_steps_trained": 2163,
            "policy_loss": 9.838538517215056e-07,
            "mean_kl_loss": -5.988538998025206e-09,
            "module_train_batch_size_mean": 186.67084597471455,
            "vf_loss": 0.9878541827201843,
            "vf_loss_unclipped": 72.7205581665039,
            "num_module_steps_trained_lifetime_throughput": 44.15285570502129
        },
        "differentiable_learners": {
            "intrinsic_attention_ppo_learner": {
                "__all_modules__": {
                    "num_env_steps_trained_lifetime": 2462380,
                    "num_env_steps_trained": 683568,
                    "num_module_steps_trained_lifetime": 201645,
                    "num_module_steps_trained": 52118,
                    "num_env_steps_trained_lifetime_throughput": 30911.484917459882
                },
                "default_policy": {
                    "num_module_steps_trained": 26149,
                    "num_module_steps_trained_lifetime": 100766,
                    "mean_kl_loss": 3.804659698403157e-09,
                    "weights_seq_no": 46.0,
                    "use_intrinsic_rewards": 1.0,
                    "vf_loss": 0.9877027273178101,
                    "vf_explained_var": 2.384185791015625e-07,
                    "entropy": 0.6918079257011414,
                    "policy_loss": 1.6356623291358119e-06,
                    "module_train_batch_size_mean": 185.11708782234263,
                    "vf_loss_unclipped": 76.46405792236328,
                    "diff_num_grad_updates_vs_sampler_policy": 43.0,
                    "total_loss": 0.48693493008613586
                },
                "intrinsic_reward_module": {
                    "diff_num_grad_updates_vs_sampler_policy": 43.0,
                    "num_module_steps_trained_lifetime": 100879,
                    "total_loss": 0.0,
                    "weights_seq_no": 46.0,
                    "num_module_steps_trained": 25969,
                    "module_train_batch_size_mean": 184.20079416699215
                }
            }
        },
        "intrinsic_reward_module": {
            "diff_num_grad_updates_vs_sampler_policy": 1.0,
            "num_trainable_parameters": 4499,
            "total_loss": 0.0,
            "weights_seq_no": 4.0,
            "num_module_steps_trained": 2155,
            "num_module_steps_trained_lifetime": 8762,
            "default_optimizer_learning_rate": 0.0005,
            "gradients_default_optimizer_global_norm": 0.0,
            "module_train_batch_size_mean": 186.89642892320404,
            "curr_entropy_coeff": 0.01,
            "num_module_steps_trained_lifetime_throughput": 43.917476693098926
        },
        "__all_modules__": {
            "num_env_steps_trained": 56964,
            "num_env_steps_trained_lifetime": 213716,
            "num_module_steps_trained": 4318,
            "num_trainable_parameters": 20502,
            "num_module_steps_trained_lifetime": 17494,
            "num_non_trainable_parameters": 0,
            "num_env_steps_trained_lifetime_throughput": 1117.352187934537,
            "num_module_steps_trained_throughput": 2096266.325515954,
            "num_module_steps_trained_lifetime_throughput": 1212175.6408212543
        }
    },
    "num_training_step_calls_per_iteration": 1,
    "evaluation": {
        "env_runners": {
            "episode_duration_sec_mean": 0.02481444030017883,
            "module_to_env_connector": {
                "timers": {
                    "connectors": {
                        "un_batch_to_individual_items": 1.9876380320995407e-05,
                        "listify_data_for_vector_env": 3.343433327341039e-05,
                        "tensor_to_numpy": 6.918135948638581e-05,
                        "remove_single_ts_time_rank_from_batch": 3.279821394402929e-05,
                        "normalize_and_clip_actions": 2.6010226428340955e-05,
                        "get_actions": 0.0002264045590331683
                    }
                },
                "connector_pipeline_timer": 0.0004939361431632863
            },
            "env_to_module_sum_episodes_length_out": 13.32508950171201,
            "env_to_module_connector": {
                "connector_pipeline_timer": 0.00020573323151777426,
                "timers": {
                    "connectors": {
                        "batch_individual_items": 4.065697222810412e-05,
                        "numpy_to_tensor": 6.479914721783988e-05,
                        "add_states_from_episodes_to_batch": 8.18856969444626e-06,
                        "add_observations_from_episodes_to_batch": 8.583192437610822e-06,
                        "add_time_dim_to_batch_and_zero_pad": 2.392134367597368e-05
                    }
                }
            },
            "env_step_timer": 7.282863387560066e-05,
            "sample": 0.166282408759818,
            "episode_len_mean": 22.6,
            "episode_return_min": 10.0,
            "episode_return_mean": 22.6,
            "num_module_steps_sampled": {
                "default_policy": 105
            },
            "num_episodes_lifetime": 20,
            "episode_len_max": 39,
            "episode_len_min": 10,
            "num_env_steps_sampled_lifetime": 4172,
            "num_agent_steps_sampled": {
                "default_agent": 105
            },
            "num_module_steps_sampled_lifetime": {
                "default_policy": 452
            },
            "num_episodes": 5,
            "agent_episode_returns_mean": {
                "default_agent": 22.6
            },
            "env_reset_timer": 0.0003289329443587994,
            "num_agent_steps_sampled_lifetime": {
                "default_agent": 452
            },
            "num_env_steps_sampled": 105,
            "env_to_module_sum_episodes_length_in": 13.32508950171201,
            "episode_return_max": 39.0,
            "weights_seq_no": 4.0,
            "module_episode_returns_mean": {
                "default_policy": 22.6
            },
            "rlmodule_inference_timer": 0.0001996325092453685,
            "time_between_sampling": 56.72857254594147
        },
        "num_healthy_workers": 1,
        "actor_manager_num_outstanding_async_reqs": 0,
        "num_remote_worker_restarts": 0
    },
    "num_env_steps_sampled_lifetime": -47092.000000000044,
    "fault_tolerance": {
        "num_healthy_workers": 0,
        "num_remote_worker_restarts": 0
    },
    "env_runner_group": {
        "actor_manager_num_outstanding_async_reqs": 0
    },
    "done": false,
    "training_iteration": 4,
    "trial_id": "5ce6b_00000",
    "date": "2025-08-11_01-00-54",
    "timestamp": 1754866854,
    "time_this_iter_s": 57.23907709121704,
    "time_total_s": 206.56043314933777,
    "pid": 28244,
    "hostname": "DESKTOP-LDQ7B16",
    "node_ip": "172.23.2.81",
    "config": {
        "exploration_config": {},
        "extra_python_environs_for_driver": {},
        "extra_python_environs_for_worker": {},
        "placement_strategy": "PACK",
        "num_gpus": 0,
        "_fake_gpus": false,
        "num_cpus_for_main_process": 6,
        "eager_tracing": true,
        "eager_max_retraces": 20,
        "tf_session_args": {
            "intra_op_parallelism_threads": 2,
            "inter_op_parallelism_threads": 2,
            "gpu_options": {
                "allow_growth": true
            },
            "log_device_placement": false,
            "device_count": {
                "CPU": 1
            },
            "allow_soft_placement": true
        },
        "local_tf_session_args": {
            "intra_op_parallelism_threads": 8,
            "inter_op_parallelism_threads": 8
        },
        "torch_compile_learner": false,
        "torch_compile_learner_what_to_compile": "forward_train",
        "torch_compile_learner_dynamo_backend": "inductor",
        "torch_compile_learner_dynamo_mode": null,
        "torch_compile_worker": false,
        "torch_compile_worker_dynamo_backend": "onnxrt",
        "torch_compile_worker_dynamo_mode": null,
        "torch_ddp_kwargs": {},
        "torch_skip_nan_gradients": false,
        "env": "CartPole-v1",
        "env_config": {},
        "observation_space": null,
        "action_space": null,
        "clip_rewards": null,
        "normalize_actions": true,
        "clip_actions": false,
        "_is_atari": null,
        "disable_env_checking": false,
        "render_env": false,
        "action_mask_key": "action_mask",
        "env_runner_cls": null,
        "num_env_runners": 0,
        "create_local_env_runner": true,
        "num_envs_per_env_runner": 1,
        "gym_env_vectorize_mode": "SYNC",
        "num_cpus_per_env_runner": 1,
        "num_gpus_per_env_runner": 0,
        "custom_resources_per_env_runner": {},
        "validate_env_runners_after_construction": true,
        "episodes_to_numpy": true,
        "max_requests_in_flight_per_env_runner": 1,
        "sample_timeout_s": 60.0,
        "_env_to_module_connector": null,
        "add_default_connectors_to_env_to_module_pipeline": true,
        "_module_to_env_connector": null,
        "add_default_connectors_to_module_to_env_pipeline": true,
        "merge_env_runner_states": "training_only",
        "broadcast_env_runner_states": true,
        "episode_lookback_horizon": 1,
        "rollout_fragment_length": "auto",
        "batch_mode": "complete_episodes",
        "compress_observations": false,
        "remote_worker_envs": false,
        "remote_env_batch_wait_ms": 0,
        "enable_tf1_exec_eagerly": false,
        "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>",
        "preprocessor_pref": "deepmind",
        "observation_filter": "NoFilter",
        "update_worker_filter_stats": true,
        "use_worker_filter_stats": true,
        "sampler_perf_stats_ema_coef": null,
        "_is_online": true,
        "num_learners": 0,
        "num_gpus_per_learner": 0,
        "num_cpus_per_learner": "auto",
        "num_aggregator_actors_per_learner": 0,
        "max_requests_in_flight_per_aggregator_actor": 3,
        "local_gpu_idx": 0,
        "max_requests_in_flight_per_learner": 3,
        "gamma": 0.99,
        "lr": 0.0005,
        "grad_clip": 0.5,
        "grad_clip_by": "global_norm",
        "_train_batch_size_per_learner": 1000,
        "train_batch_size": 4000,
        "num_epochs": 2,
        "minibatch_size": 200,
        "shuffle_batch_per_epoch": true,
        "model": {
            "fcnet_hiddens": [
                256,
                256
            ],
            "fcnet_activation": "tanh",
            "fcnet_weights_initializer": null,
            "fcnet_weights_initializer_config": null,
            "fcnet_bias_initializer": null,
            "fcnet_bias_initializer_config": null,
            "conv_filters": null,
            "conv_activation": "relu",
            "conv_kernel_initializer": null,
            "conv_kernel_initializer_config": null,
            "conv_bias_initializer": null,
            "conv_bias_initializer_config": null,
            "conv_transpose_kernel_initializer": null,
            "conv_transpose_kernel_initializer_config": null,
            "conv_transpose_bias_initializer": null,
            "conv_transpose_bias_initializer_config": null,
            "post_fcnet_hiddens": [],
            "post_fcnet_activation": "relu",
            "post_fcnet_weights_initializer": null,
            "post_fcnet_weights_initializer_config": null,
            "post_fcnet_bias_initializer": null,
            "post_fcnet_bias_initializer_config": null,
            "free_log_std": false,
            "log_std_clip_param": 20.0,
            "no_final_linear": false,
            "vf_share_layers": false,
            "use_lstm": false,
            "max_seq_len": 20,
            "lstm_cell_size": 256,
            "lstm_use_prev_action": false,
            "lstm_use_prev_reward": false,
            "lstm_weights_initializer": null,
            "lstm_weights_initializer_config": null,
            "lstm_bias_initializer": null,
            "lstm_bias_initializer_config": null,
            "_time_major": false,
            "use_attention": false,
            "attention_num_transformer_units": 1,
            "attention_dim": 64,
            "attention_num_heads": 1,
            "attention_head_dim": 32,
            "attention_memory_inference": 50,
            "attention_memory_training": 50,
            "attention_position_wise_mlp_dim": 32,
            "attention_init_gru_gate_bias": 2.0,
            "attention_use_n_prev_actions": 0,
            "attention_use_n_prev_rewards": 0,
            "framestack": true,
            "dim": 84,
            "grayscale": false,
            "zero_mean": true,
            "custom_model": null,
            "custom_model_config": {},
            "custom_action_dist": null,
            "custom_preprocessor": null,
            "encoder_latent_dim": null,
            "always_check_shapes": false,
            "lstm_use_prev_action_reward": -1,
            "_use_default_native_models": -1,
            "_disable_preprocessor_api": false,
            "_disable_action_flattening": false
        },
        "_learner_connector": null,
        "add_default_connectors_to_learner_pipeline": true,
        "learner_config_dict": {
            "intrinsic_reward_coeff": 0.01
        },
        "optimizer": {},
        "_learner_class": "<class 'source.intrinsic_attention_ppo.learners.IntrinsicAttentionMetaLearner.IntrinsicAttentionMetaLearner'>",
        "callbacks_on_algorithm_init": null,
        "callbacks_on_env_runners_recreated": null,
        "callbacks_on_offline_eval_runners_recreated": null,
        "callbacks_on_checkpoint_loaded": null,
        "callbacks_on_environment_created": null,
        "callbacks_on_episode_created": null,
        "callbacks_on_episode_start": null,
        "callbacks_on_episode_step": null,
        "callbacks_on_episode_end": null,
        "callbacks_on_evaluate_start": null,
        "callbacks_on_evaluate_end": null,
        "callbacks_on_evaluate_offline_start": null,
        "callbacks_on_evaluate_offline_end": null,
        "callbacks_on_sample_end": null,
        "callbacks_on_train_result": null,
        "explore": true,
        "enable_rl_module_and_learner": true,
        "enable_env_runner_and_connector_v2": true,
        "_prior_exploration_config": {
            "type": "StochasticSampling"
        },
        "count_steps_by": "env_steps",
        "policy_map_capacity": 100,
        "policy_mapping_fn": "<function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7553da886ac0>",
        "policies_to_train": null,
        "policy_states_are_swappable": false,
        "observation_fn": null,
        "offline_data_class": null,
        "input_read_method": "read_parquet",
        "input_read_method_kwargs": {},
        "input_read_schema": {},
        "input_read_episodes": false,
        "input_read_sample_batches": false,
        "input_read_batch_size": null,
        "input_filesystem": null,
        "input_filesystem_kwargs": {},
        "input_compress_columns": [
            "obs",
            "new_obs"
        ],
        "input_spaces_jsonable": true,
        "materialize_data": false,
        "materialize_mapped_data": true,
        "map_batches_kwargs": {},
        "iter_batches_kwargs": {},
        "ignore_final_observation": false,
        "prelearner_class": null,
        "prelearner_buffer_class": null,
        "prelearner_buffer_kwargs": {},
        "prelearner_module_synch_period": 10,
        "dataset_num_iters_per_learner": null,
        "input_config": {},
        "actions_in_input_normalized": false,
        "postprocess_inputs": false,
        "shuffle_buffer_size": 0,
        "output": null,
        "output_config": {},
        "output_compress_columns": [
            "obs",
            "new_obs"
        ],
        "output_max_file_size": 67108864,
        "output_max_rows_per_file": null,
        "output_write_remaining_data": false,
        "output_write_method": "write_parquet",
        "output_write_method_kwargs": {},
        "output_filesystem": null,
        "output_filesystem_kwargs": {},
        "output_write_episodes": true,
        "offline_sampling": false,
        "evaluation_interval": 1,
        "evaluation_duration": 5,
        "evaluation_duration_unit": "episodes",
        "evaluation_sample_timeout_s": 120.0,
        "evaluation_auto_duration_min_env_steps_per_sample": 100,
        "evaluation_auto_duration_max_env_steps_per_sample": 2000,
        "evaluation_parallel_to_training": false,
        "evaluation_force_reset_envs_before_iteration": true,
        "evaluation_config": null,
        "off_policy_estimation_methods": {},
        "ope_split_batch_by_episode": true,
        "evaluation_num_env_runners": 1,
        "in_evaluation": false,
        "sync_filters_on_rollout_workers_timeout_s": 10.0,
        "offline_evaluation_interval": null,
        "num_offline_eval_runners": 0,
        "offline_loss_for_module_fn": null,
        "offline_evaluation_duration": 1,
        "offline_evaluation_parallel_to_training": false,
        "offline_evaluation_timeout_s": 120.0,
        "num_cpus_per_offline_eval_runner": 1,
        "num_gpus_per_offline_eval_runner": 0,
        "custom_resources_per_offline_eval_runner": {},
        "restart_failed_offline_eval_runners": true,
        "ignore_offline_eval_runner_failures": false,
        "max_num_offline_eval_runner_restarts": 1000,
        "offline_eval_runner_restore_timeout_s": 1800.0,
        "max_requests_in_flight_per_offline_eval_runner": 1,
        "validate_offline_eval_runners_after_construction": true,
        "offline_eval_runner_health_probe_timeout_s": 30.0,
        "offline_eval_rl_module_inference_only": false,
        "broadcast_offline_eval_runner_states": false,
        "offline_eval_batch_size_per_runner": 256,
        "dataset_num_iters_per_eval_runner": 1,
        "keep_per_episode_custom_metrics": false,
        "metrics_episode_collection_timeout_s": 60.0,
        "metrics_num_episodes_for_smoothing": 100,
        "min_time_s_per_iteration": null,
        "min_train_timesteps_per_iteration": 0,
        "min_sample_timesteps_per_iteration": 0,
        "log_gradients": false,
        "export_native_model_files": false,
        "checkpoint_trainable_policies_only": false,
        "logger_creator": null,
        "logger_config": null,
        "log_level": "WARN",
        "log_sys_usage": true,
        "fake_sampler": false,
        "seed": 42,
        "restart_failed_env_runners": true,
        "ignore_env_runner_failures": false,
        "max_num_env_runner_restarts": 1000,
        "delay_between_env_runner_restarts_s": 60.0,
        "restart_failed_sub_environments": false,
        "num_consecutive_env_runner_failures_tolerance": 100,
        "env_runner_health_probe_timeout_s": 30.0,
        "env_runner_restore_timeout_s": 1800.0,
        "_model_config": {},
        "_rl_module_spec": "MultiRLModuleSpec(multi_rl_module_class=<class 'ray.rllib.core.rl_module.multi_rl_module.MultiRLModule'>, observation_space=None, action_space=None, inference_only=False, model_config=None, rl_module_specs={'default_policy': RLModuleSpec(module_class=<class 'source.intrinsic_attention_ppo.rl_modules.DifferentiablePPOModule.DifferentiablePPOModule'>, observation_space=None, action_space=None, inference_only=False, learner_only=False, model_config={'vf_share_layers': True, 'embedding_dim': 32, 'max_seq_len': 101, 'policy_head_hidden_sizes': [32, 64, 32], 'value_head_hidden_sizes': [32, 64, 32], 'embedding_hidden_sizes': [32, 64, 32]}, catalog_class=None, load_state_path=None, model_config_dict=None), 'intrinsic_reward_module': RLModuleSpec(module_class=<class 'source.intrinsic_attention_ppo.rl_modules.IntrinsicAttentionModule.IntrinsicAttentionModule'>, observation_space=None, action_space=None, inference_only=False, learner_only=True, model_config={'intrinsic_reward_network': {'encoder_hidden_sizes': [], 'encoding_dim': 1, 'num_heads': 1, 'head_hidden_sizes': None, 'layers': [{'type': 'attention'}]}, 'extrinsic_value_hidden_layers': [32, 64, 32], 'vf_share_layers': True, 'max_seq_len': 101}, catalog_class=None, load_state_path=None, model_config_dict=None)}, load_state_path=None, modules_to_load=None, module_specs={'default_policy': RLModuleSpec(module_class=<class 'source.intrinsic_attention_ppo.rl_modules.DifferentiablePPOModule.DifferentiablePPOModule'>, observation_space=None, action_space=None, inference_only=False, learner_only=False, model_config={'vf_share_layers': True, 'embedding_dim': 32, 'max_seq_len': 101, 'policy_head_hidden_sizes': [32, 64, 32], 'value_head_hidden_sizes': [32, 64, 32], 'embedding_hidden_sizes': [32, 64, 32]}, catalog_class=None, load_state_path=None, model_config_dict=None), 'intrinsic_reward_module': RLModuleSpec(module_class=<class 'source.intrinsic_attention_ppo.rl_modules.IntrinsicAttentionModule.IntrinsicAttentionModule'>, observation_space=None, action_space=None, inference_only=False, learner_only=True, model_config={'intrinsic_reward_network': {'encoder_hidden_sizes': [], 'encoding_dim': 1, 'num_heads': 1, 'head_hidden_sizes': None, 'layers': [{'type': 'attention'}]}, 'extrinsic_value_hidden_layers': [32, 64, 32], 'vf_share_layers': True, 'max_seq_len': 101}, catalog_class=None, load_state_path=None, model_config_dict=None)})",
        "algorithm_config_overrides_per_module": {
            "intrinsic_reward_module": {
                "lr": 0.0005
            }
        },
        "_per_module_overrides": {},
        "_validate_config": true,
        "_use_msgpack_checkpoints": false,
        "_torch_grad_scaler_class": null,
        "_torch_lr_scheduler_classes": null,
        "_tf_policy_handles_more_than_one_loss": false,
        "_disable_preprocessor_api": false,
        "_disable_action_flattening": false,
        "_disable_initialize_loss_from_dummy_batch": false,
        "_dont_auto_sync_env_runner_states": false,
        "env_task_fn": -1,
        "enable_connectors": -1,
        "simple_optimizer": false,
        "policy_map_cache": -1,
        "worker_cls": -1,
        "synchronize_filters": -1,
        "enable_async_evaluation": -1,
        "custom_async_evaluation_function": -1,
        "_enable_rl_module_api": -1,
        "auto_wrap_old_gym_envs": -1,
        "always_attach_evaluation_results": -1,
        "replay_sequence_length": null,
        "_disable_execution_plan_api": -1,
        "use_critic": true,
        "use_gae": true,
        "use_kl_loss": true,
        "kl_coeff": 0.2,
        "kl_target": 0.01,
        "vf_loss_coeff": 0.5,
        "entropy_coeff": 0.01,
        "clip_param": 0.2,
        "vf_clip_param": 1.0,
        "entropy_coeff_schedule": null,
        "lr_schedule": null,
        "sgd_minibatch_size": -1,
        "vf_share_layers": -1,
        "differentiable_learner_configs": [
            "DifferentiableLearnerConfig(learner_class=<class 'source.intrinsic_attention_ppo.learners.IntrinsicAttentionPPOLearner.IntrinsicAttentionPPOLearner'>, learner_connector=None, add_default_connectors_to_learner_pipeline=True, is_multi_agent=False, policies_to_update=['default_policy'], lr=0.0003, num_total_minibatches=0, num_epochs=2, minibatch_size=200, shuffle_batch_per_epoch=True)"
        ],
        "__stdout_file__": null,
        "__stderr_file__": null,
        "lambda": 0.95,
        "input": "sampler",
        "policies": {
            "default_policy": [
                null,
                null,
                null,
                null
            ]
        },
        "callbacks": "<class 'ray.rllib.callbacks.callbacks.RLlibCallback'>",
        "create_env_on_driver": false,
        "custom_eval_function": null,
        "framework": "torch"
    },
    "time_since_restore": 206.56043314933777,
    "iterations_since_restore": 4,
    "perf": {
        "cpu_util_percent": 43.11463414634147,
        "ram_util_percent": 65.92926829268292
    }
}
{
    "timers": {
        "training_iteration": 42.62724458759423,
        "restore_env_runners": 3.849806738127991e-05,
        "training_step": 42.62686235763273,
        "env_runner_sampling_timer": 1.1245868896210005,
        "learner_update_timer": 41.39065686610722,
        "synch_weights": 0.0031218823016657083,
        "restore_eval_env_runners": 2.5087305020082568e-05,
        "evaluation_iteration": 0.18267479536303322,
        "synch_eval_env_connectors": 0.0009590900577326537,
        "synch_env_connectors": 1.0142071946160286e-05
    },
    "env_runners": {
        "env_to_module_connector": {
            "timers": {
                "connectors": {
                    "batch_individual_items": 3.9387526859955424e-05,
                    "numpy_to_tensor": 6.281850848662333e-05,
                    "add_states_from_episodes_to_batch": 7.43860361800215e-06,
                    "add_observations_from_episodes_to_batch": 8.163272810688575e-06,
                    "add_time_dim_to_batch_and_zero_pad": 2.3590824891798744e-05
                }
            },
            "connector_pipeline_timer": 0.00020048815953275148
        },
        "rlmodule_inference_timer": 0.0002039259752708695,
        "sample": 0.026708557726228866,
        "num_module_steps_sampled_lifetime": {
            "default_policy": -66230.00000000006
        },
        "module_episode_returns_mean": {
            "default_policy": 22.96545454545454
        },
        "time_between_sampling": 0.9586307094004681,
        "num_episodes_lifetime": -2971.0,
        "num_env_steps_sampled": 1018.0,
        "num_agent_steps_sampled": {
            "default_agent": 1018.0
        },
        "episode_len_max": 117,
        "module_to_env_connector": {
            "timers": {
                "connectors": {
                    "remove_single_ts_time_rank_from_batch": 3.236787193124581e-05,
                    "normalize_and_clip_actions": 2.5179476492979815e-05,
                    "listify_data_for_vector_env": 3.353308535660997e-05,
                    "un_batch_to_individual_items": 1.9626755388853612e-05,
                    "get_actions": 0.0002128258718926577,
                    "tensor_to_numpy": 6.399071341927324e-05
                }
            },
            "connector_pipeline_timer": 0.000472144942034573
        },
        "env_to_module_sum_episodes_length_in": 17.96220076923004,
        "num_agent_steps_sampled_lifetime": {
            "default_agent": -66230.00000000006
        },
        "env_to_module_sum_episodes_length_out": 17.96220076923004,
        "episode_return_max": 117.0,
        "episode_duration_sec_mean": 0.02494429926072453,
        "episode_len_min": 8,
        "episode_len_mean": 22.96545454545454,
        "agent_episode_returns_mean": {
            "default_agent": 22.96545454545454
        },
        "num_env_steps_sampled_lifetime": -66230.00000000006,
        "num_module_steps_sampled": {
            "default_policy": 1018.0
        },
        "weights_seq_no": 4.0,
        "episode_return_min": 8.0,
        "episode_return_mean": 22.96545454545454,
        "num_episodes": 44.0,
        "env_step_timer": 7.374409765679589e-05,
        "env_reset_timer": 0.0002702038657743457,
        "num_env_steps_sampled_lifetime_throughput": 781.5725271240844
    },
    "__all_modules__": {
        "learner_connector_sum_episodes_length_in": 1008.4415717799998,
        "learner_connector": {
            "connector_pipeline_timer": 0.08820472311946297,
            "timers": {
                "connectors": {
                    "add_one_ts_to_episodes_and_truncate": 0.006069170702076854,
                    "add_observations_from_episodes_to_batch": 0.0006279701111237422,
                    "add_columns_from_episodes_to_train_batch": 0.01962979486024995,
                    "add_time_dim_to_batch_and_zero_pad": 0.058721762538266685,
                    "add_states_from_episodes_to_batch": 0.001352859952596959,
                    "batch_individual_items": 0.0012008755547620565,
                    "numpy_to_tensor": 0.00018101212894775645
                }
            }
        },
        "learner_connector_sum_episodes_length_out": 1052.5201787699996
    },
    "learners": {
        "default_policy": {
            "diff_num_grad_updates_vs_sampler_policy": 1.0,
            "num_trainable_parameters": 16003,
            "num_module_steps_trained_lifetime": 10983,
            "total_loss": 0.48792779445648193,
            "curr_kl_coeff": 0.0062500000931322575,
            "weights_seq_no": 5.0,
            "curr_entropy_coeff": 0.01,
            "use_intrinsic_rewards": 0.0,
            "vf_explained_var": -0.000457763671875,
            "entropy": 0.6917361617088318,
            "num_module_steps_trained": 2251,
            "policy_loss": -4.8400226660305634e-05,
            "mean_kl_loss": 9.589819001121214e-07,
            "module_train_batch_size_mean": 186.7789247444781,
            "vf_loss": 0.9897870421409607,
            "vf_loss_unclipped": 96.57169342041016,
            "num_module_steps_trained_lifetime_throughput": 44.028087105107154
        },
        "differentiable_learners": {
            "intrinsic_attention_ppo_learner": {
                "__all_modules__": {
                    "num_env_steps_trained_lifetime": 3116860,
                    "num_env_steps_trained": 654480,
                    "num_module_steps_trained_lifetime": 256020,
                    "num_module_steps_trained": 54375,
                    "num_env_steps_trained_lifetime_throughput": 30268.87156366698
                },
                "default_policy": {
                    "num_module_steps_trained": 27298,
                    "num_module_steps_trained_lifetime": 128064,
                    "mean_kl_loss": 9.284403859055601e-07,
                    "weights_seq_no": 58.0,
                    "use_intrinsic_rewards": 1.0,
                    "vf_loss": 0.9886887669563293,
                    "vf_explained_var": 1.1920928955078125e-07,
                    "entropy": 0.691735029220581,
                    "policy_loss": -0.00015656383766327053,
                    "module_train_batch_size_mean": 188.67113253746322,
                    "vf_loss_unclipped": 95.04705810546875,
                    "diff_num_grad_updates_vs_sampler_policy": 54.0,
                    "total_loss": 0.48727065324783325
                },
                "intrinsic_reward_module": {
                    "diff_num_grad_updates_vs_sampler_policy": 54.0,
                    "num_module_steps_trained_lifetime": 127956,
                    "total_loss": 0.0,
                    "weights_seq_no": 58.0,
                    "num_module_steps_trained": 27077,
                    "module_train_batch_size_mean": 187.3624532644166
                }
            }
        },
        "intrinsic_reward_module": {
            "diff_num_grad_updates_vs_sampler_policy": 1.0,
            "num_trainable_parameters": 4499,
            "total_loss": 0.0,
            "weights_seq_no": 5.0,
            "num_module_steps_trained": 2259,
            "num_module_steps_trained_lifetime": 11021,
            "default_optimizer_learning_rate": 0.0005,
            "gradients_default_optimizer_global_norm": 0.0,
            "module_train_batch_size_mean": 187.0342101849154,
            "curr_entropy_coeff": 0.01,
            "num_module_steps_trained_lifetime_throughput": 43.809391910854615
        },
        "__all_modules__": {
            "num_env_steps_trained": 54540,
            "num_env_steps_trained_lifetime": 268256,
            "num_module_steps_trained": 4510,
            "num_trainable_parameters": 20502,
            "num_module_steps_trained_lifetime": 22004,
            "num_non_trainable_parameters": 0,
            "num_env_steps_trained_lifetime_throughput": 1113.3018585663121,
            "num_module_steps_trained_throughput": 2043978.041986982,
            "num_module_steps_trained_lifetime_throughput": 1205206.370021815
        }
    },
    "num_training_step_calls_per_iteration": 1,
    "evaluation": {
        "env_runners": {
            "episode_duration_sec_mean": 0.02821225168008823,
            "module_to_env_connector": {
                "timers": {
                    "connectors": {
                        "un_batch_to_individual_items": 2.4696691821527734e-05,
                        "listify_data_for_vector_env": 4.431980483395223e-05,
                        "tensor_to_numpy": 8.6415049528475e-05,
                        "remove_single_ts_time_rank_from_batch": 4.5534646787919794e-05,
                        "normalize_and_clip_actions": 3.746241495737834e-05,
                        "get_actions": 0.0003379365143928646
                    }
                },
                "connector_pipeline_timer": 0.0007042598616860624
            },
            "env_to_module_sum_episodes_length_out": 16.84112204181965,
            "env_to_module_connector": {
                "connector_pipeline_timer": 0.00025916466274147,
                "timers": {
                    "connectors": {
                        "batch_individual_items": 4.9470520161330017e-05,
                        "numpy_to_tensor": 9.09525876616268e-05,
                        "add_states_from_episodes_to_batch": 1.0187386481507885e-05,
                        "add_observations_from_episodes_to_batch": 1.1053220778522074e-05,
                        "add_time_dim_to_batch_and_zero_pad": 2.933832164102992e-05
                    }
                }
            },
            "env_step_timer": 9.470702605793521e-05,
            "sample": 0.16683759122217587,
            "episode_len_mean": 23.44,
            "episode_return_min": 10.0,
            "episode_return_mean": 23.44,
            "num_module_steps_sampled": {
                "default_policy": 134
            },
            "num_episodes_lifetime": 25,
            "episode_len_max": 57,
            "episode_len_min": 10,
            "num_env_steps_sampled_lifetime": 5219,
            "num_agent_steps_sampled": {
                "default_agent": 134
            },
            "num_module_steps_sampled_lifetime": {
                "default_policy": 586
            },
            "num_episodes": 5,
            "agent_episode_returns_mean": {
                "default_agent": 23.44
            },
            "env_reset_timer": 0.0003272346349606642,
            "num_agent_steps_sampled_lifetime": {
                "default_agent": 586
            },
            "num_env_steps_sampled": 134,
            "env_to_module_sum_episodes_length_in": 16.84112204181965,
            "episode_return_max": 57.0,
            "weights_seq_no": 5.0,
            "module_episode_returns_mean": {
                "default_policy": 23.44
            },
            "rlmodule_inference_timer": 0.0002585536326829924,
            "time_between_sampling": 56.69211644480209
        },
        "num_healthy_workers": 1,
        "actor_manager_num_outstanding_async_reqs": 0,
        "num_remote_worker_restarts": 0
    },
    "num_env_steps_sampled_lifetime": -66230.00000000006,
    "fault_tolerance": {
        "num_healthy_workers": 0,
        "num_remote_worker_restarts": 0
    },
    "env_runner_group": {
        "actor_manager_num_outstanding_async_reqs": 0
    },
    "done": false,
    "training_iteration": 5,
    "trial_id": "5ce6b_00000",
    "date": "2025-08-11_01-01-47",
    "timestamp": 1754866907,
    "time_this_iter_s": 53.25977921485901,
    "time_total_s": 259.8202123641968,
    "pid": 28244,
    "hostname": "DESKTOP-LDQ7B16",
    "node_ip": "172.23.2.81",
    "config": {
        "exploration_config": {},
        "extra_python_environs_for_driver": {},
        "extra_python_environs_for_worker": {},
        "placement_strategy": "PACK",
        "num_gpus": 0,
        "_fake_gpus": false,
        "num_cpus_for_main_process": 6,
        "eager_tracing": true,
        "eager_max_retraces": 20,
        "tf_session_args": {
            "intra_op_parallelism_threads": 2,
            "inter_op_parallelism_threads": 2,
            "gpu_options": {
                "allow_growth": true
            },
            "log_device_placement": false,
            "device_count": {
                "CPU": 1
            },
            "allow_soft_placement": true
        },
        "local_tf_session_args": {
            "intra_op_parallelism_threads": 8,
            "inter_op_parallelism_threads": 8
        },
        "torch_compile_learner": false,
        "torch_compile_learner_what_to_compile": "forward_train",
        "torch_compile_learner_dynamo_backend": "inductor",
        "torch_compile_learner_dynamo_mode": null,
        "torch_compile_worker": false,
        "torch_compile_worker_dynamo_backend": "onnxrt",
        "torch_compile_worker_dynamo_mode": null,
        "torch_ddp_kwargs": {},
        "torch_skip_nan_gradients": false,
        "env": "CartPole-v1",
        "env_config": {},
        "observation_space": null,
        "action_space": null,
        "clip_rewards": null,
        "normalize_actions": true,
        "clip_actions": false,
        "_is_atari": null,
        "disable_env_checking": false,
        "render_env": false,
        "action_mask_key": "action_mask",
        "env_runner_cls": null,
        "num_env_runners": 0,
        "create_local_env_runner": true,
        "num_envs_per_env_runner": 1,
        "gym_env_vectorize_mode": "SYNC",
        "num_cpus_per_env_runner": 1,
        "num_gpus_per_env_runner": 0,
        "custom_resources_per_env_runner": {},
        "validate_env_runners_after_construction": true,
        "episodes_to_numpy": true,
        "max_requests_in_flight_per_env_runner": 1,
        "sample_timeout_s": 60.0,
        "_env_to_module_connector": null,
        "add_default_connectors_to_env_to_module_pipeline": true,
        "_module_to_env_connector": null,
        "add_default_connectors_to_module_to_env_pipeline": true,
        "merge_env_runner_states": "training_only",
        "broadcast_env_runner_states": true,
        "episode_lookback_horizon": 1,
        "rollout_fragment_length": "auto",
        "batch_mode": "complete_episodes",
        "compress_observations": false,
        "remote_worker_envs": false,
        "remote_env_batch_wait_ms": 0,
        "enable_tf1_exec_eagerly": false,
        "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>",
        "preprocessor_pref": "deepmind",
        "observation_filter": "NoFilter",
        "update_worker_filter_stats": true,
        "use_worker_filter_stats": true,
        "sampler_perf_stats_ema_coef": null,
        "_is_online": true,
        "num_learners": 0,
        "num_gpus_per_learner": 0,
        "num_cpus_per_learner": "auto",
        "num_aggregator_actors_per_learner": 0,
        "max_requests_in_flight_per_aggregator_actor": 3,
        "local_gpu_idx": 0,
        "max_requests_in_flight_per_learner": 3,
        "gamma": 0.99,
        "lr": 0.0005,
        "grad_clip": 0.5,
        "grad_clip_by": "global_norm",
        "_train_batch_size_per_learner": 1000,
        "train_batch_size": 4000,
        "num_epochs": 2,
        "minibatch_size": 200,
        "shuffle_batch_per_epoch": true,
        "model": {
            "fcnet_hiddens": [
                256,
                256
            ],
            "fcnet_activation": "tanh",
            "fcnet_weights_initializer": null,
            "fcnet_weights_initializer_config": null,
            "fcnet_bias_initializer": null,
            "fcnet_bias_initializer_config": null,
            "conv_filters": null,
            "conv_activation": "relu",
            "conv_kernel_initializer": null,
            "conv_kernel_initializer_config": null,
            "conv_bias_initializer": null,
            "conv_bias_initializer_config": null,
            "conv_transpose_kernel_initializer": null,
            "conv_transpose_kernel_initializer_config": null,
            "conv_transpose_bias_initializer": null,
            "conv_transpose_bias_initializer_config": null,
            "post_fcnet_hiddens": [],
            "post_fcnet_activation": "relu",
            "post_fcnet_weights_initializer": null,
            "post_fcnet_weights_initializer_config": null,
            "post_fcnet_bias_initializer": null,
            "post_fcnet_bias_initializer_config": null,
            "free_log_std": false,
            "log_std_clip_param": 20.0,
            "no_final_linear": false,
            "vf_share_layers": false,
            "use_lstm": false,
            "max_seq_len": 20,
            "lstm_cell_size": 256,
            "lstm_use_prev_action": false,
            "lstm_use_prev_reward": false,
            "lstm_weights_initializer": null,
            "lstm_weights_initializer_config": null,
            "lstm_bias_initializer": null,
            "lstm_bias_initializer_config": null,
            "_time_major": false,
            "use_attention": false,
            "attention_num_transformer_units": 1,
            "attention_dim": 64,
            "attention_num_heads": 1,
            "attention_head_dim": 32,
            "attention_memory_inference": 50,
            "attention_memory_training": 50,
            "attention_position_wise_mlp_dim": 32,
            "attention_init_gru_gate_bias": 2.0,
            "attention_use_n_prev_actions": 0,
            "attention_use_n_prev_rewards": 0,
            "framestack": true,
            "dim": 84,
            "grayscale": false,
            "zero_mean": true,
            "custom_model": null,
            "custom_model_config": {},
            "custom_action_dist": null,
            "custom_preprocessor": null,
            "encoder_latent_dim": null,
            "always_check_shapes": false,
            "lstm_use_prev_action_reward": -1,
            "_use_default_native_models": -1,
            "_disable_preprocessor_api": false,
            "_disable_action_flattening": false
        },
        "_learner_connector": null,
        "add_default_connectors_to_learner_pipeline": true,
        "learner_config_dict": {
            "intrinsic_reward_coeff": 0.01
        },
        "optimizer": {},
        "_learner_class": "<class 'source.intrinsic_attention_ppo.learners.IntrinsicAttentionMetaLearner.IntrinsicAttentionMetaLearner'>",
        "callbacks_on_algorithm_init": null,
        "callbacks_on_env_runners_recreated": null,
        "callbacks_on_offline_eval_runners_recreated": null,
        "callbacks_on_checkpoint_loaded": null,
        "callbacks_on_environment_created": null,
        "callbacks_on_episode_created": null,
        "callbacks_on_episode_start": null,
        "callbacks_on_episode_step": null,
        "callbacks_on_episode_end": null,
        "callbacks_on_evaluate_start": null,
        "callbacks_on_evaluate_end": null,
        "callbacks_on_evaluate_offline_start": null,
        "callbacks_on_evaluate_offline_end": null,
        "callbacks_on_sample_end": null,
        "callbacks_on_train_result": null,
        "explore": true,
        "enable_rl_module_and_learner": true,
        "enable_env_runner_and_connector_v2": true,
        "_prior_exploration_config": {
            "type": "StochasticSampling"
        },
        "count_steps_by": "env_steps",
        "policy_map_capacity": 100,
        "policy_mapping_fn": "<function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7553da886ac0>",
        "policies_to_train": null,
        "policy_states_are_swappable": false,
        "observation_fn": null,
        "offline_data_class": null,
        "input_read_method": "read_parquet",
        "input_read_method_kwargs": {},
        "input_read_schema": {},
        "input_read_episodes": false,
        "input_read_sample_batches": false,
        "input_read_batch_size": null,
        "input_filesystem": null,
        "input_filesystem_kwargs": {},
        "input_compress_columns": [
            "obs",
            "new_obs"
        ],
        "input_spaces_jsonable": true,
        "materialize_data": false,
        "materialize_mapped_data": true,
        "map_batches_kwargs": {},
        "iter_batches_kwargs": {},
        "ignore_final_observation": false,
        "prelearner_class": null,
        "prelearner_buffer_class": null,
        "prelearner_buffer_kwargs": {},
        "prelearner_module_synch_period": 10,
        "dataset_num_iters_per_learner": null,
        "input_config": {},
        "actions_in_input_normalized": false,
        "postprocess_inputs": false,
        "shuffle_buffer_size": 0,
        "output": null,
        "output_config": {},
        "output_compress_columns": [
            "obs",
            "new_obs"
        ],
        "output_max_file_size": 67108864,
        "output_max_rows_per_file": null,
        "output_write_remaining_data": false,
        "output_write_method": "write_parquet",
        "output_write_method_kwargs": {},
        "output_filesystem": null,
        "output_filesystem_kwargs": {},
        "output_write_episodes": true,
        "offline_sampling": false,
        "evaluation_interval": 1,
        "evaluation_duration": 5,
        "evaluation_duration_unit": "episodes",
        "evaluation_sample_timeout_s": 120.0,
        "evaluation_auto_duration_min_env_steps_per_sample": 100,
        "evaluation_auto_duration_max_env_steps_per_sample": 2000,
        "evaluation_parallel_to_training": false,
        "evaluation_force_reset_envs_before_iteration": true,
        "evaluation_config": null,
        "off_policy_estimation_methods": {},
        "ope_split_batch_by_episode": true,
        "evaluation_num_env_runners": 1,
        "in_evaluation": false,
        "sync_filters_on_rollout_workers_timeout_s": 10.0,
        "offline_evaluation_interval": null,
        "num_offline_eval_runners": 0,
        "offline_loss_for_module_fn": null,
        "offline_evaluation_duration": 1,
        "offline_evaluation_parallel_to_training": false,
        "offline_evaluation_timeout_s": 120.0,
        "num_cpus_per_offline_eval_runner": 1,
        "num_gpus_per_offline_eval_runner": 0,
        "custom_resources_per_offline_eval_runner": {},
        "restart_failed_offline_eval_runners": true,
        "ignore_offline_eval_runner_failures": false,
        "max_num_offline_eval_runner_restarts": 1000,
        "offline_eval_runner_restore_timeout_s": 1800.0,
        "max_requests_in_flight_per_offline_eval_runner": 1,
        "validate_offline_eval_runners_after_construction": true,
        "offline_eval_runner_health_probe_timeout_s": 30.0,
        "offline_eval_rl_module_inference_only": false,
        "broadcast_offline_eval_runner_states": false,
        "offline_eval_batch_size_per_runner": 256,
        "dataset_num_iters_per_eval_runner": 1,
        "keep_per_episode_custom_metrics": false,
        "metrics_episode_collection_timeout_s": 60.0,
        "metrics_num_episodes_for_smoothing": 100,
        "min_time_s_per_iteration": null,
        "min_train_timesteps_per_iteration": 0,
        "min_sample_timesteps_per_iteration": 0,
        "log_gradients": false,
        "export_native_model_files": false,
        "checkpoint_trainable_policies_only": false,
        "logger_creator": null,
        "logger_config": null,
        "log_level": "WARN",
        "log_sys_usage": true,
        "fake_sampler": false,
        "seed": 42,
        "restart_failed_env_runners": true,
        "ignore_env_runner_failures": false,
        "max_num_env_runner_restarts": 1000,
        "delay_between_env_runner_restarts_s": 60.0,
        "restart_failed_sub_environments": false,
        "num_consecutive_env_runner_failures_tolerance": 100,
        "env_runner_health_probe_timeout_s": 30.0,
        "env_runner_restore_timeout_s": 1800.0,
        "_model_config": {},
        "_rl_module_spec": "MultiRLModuleSpec(multi_rl_module_class=<class 'ray.rllib.core.rl_module.multi_rl_module.MultiRLModule'>, observation_space=None, action_space=None, inference_only=False, model_config=None, rl_module_specs={'default_policy': RLModuleSpec(module_class=<class 'source.intrinsic_attention_ppo.rl_modules.DifferentiablePPOModule.DifferentiablePPOModule'>, observation_space=None, action_space=None, inference_only=False, learner_only=False, model_config={'vf_share_layers': True, 'embedding_dim': 32, 'max_seq_len': 101, 'policy_head_hidden_sizes': [32, 64, 32], 'value_head_hidden_sizes': [32, 64, 32], 'embedding_hidden_sizes': [32, 64, 32]}, catalog_class=None, load_state_path=None, model_config_dict=None), 'intrinsic_reward_module': RLModuleSpec(module_class=<class 'source.intrinsic_attention_ppo.rl_modules.IntrinsicAttentionModule.IntrinsicAttentionModule'>, observation_space=None, action_space=None, inference_only=False, learner_only=True, model_config={'intrinsic_reward_network': {'encoder_hidden_sizes': [], 'encoding_dim': 1, 'num_heads': 1, 'head_hidden_sizes': None, 'layers': [{'type': 'attention'}]}, 'extrinsic_value_hidden_layers': [32, 64, 32], 'vf_share_layers': True, 'max_seq_len': 101}, catalog_class=None, load_state_path=None, model_config_dict=None)}, load_state_path=None, modules_to_load=None, module_specs={'default_policy': RLModuleSpec(module_class=<class 'source.intrinsic_attention_ppo.rl_modules.DifferentiablePPOModule.DifferentiablePPOModule'>, observation_space=None, action_space=None, inference_only=False, learner_only=False, model_config={'vf_share_layers': True, 'embedding_dim': 32, 'max_seq_len': 101, 'policy_head_hidden_sizes': [32, 64, 32], 'value_head_hidden_sizes': [32, 64, 32], 'embedding_hidden_sizes': [32, 64, 32]}, catalog_class=None, load_state_path=None, model_config_dict=None), 'intrinsic_reward_module': RLModuleSpec(module_class=<class 'source.intrinsic_attention_ppo.rl_modules.IntrinsicAttentionModule.IntrinsicAttentionModule'>, observation_space=None, action_space=None, inference_only=False, learner_only=True, model_config={'intrinsic_reward_network': {'encoder_hidden_sizes': [], 'encoding_dim': 1, 'num_heads': 1, 'head_hidden_sizes': None, 'layers': [{'type': 'attention'}]}, 'extrinsic_value_hidden_layers': [32, 64, 32], 'vf_share_layers': True, 'max_seq_len': 101}, catalog_class=None, load_state_path=None, model_config_dict=None)})",
        "algorithm_config_overrides_per_module": {
            "intrinsic_reward_module": {
                "lr": 0.0005
            }
        },
        "_per_module_overrides": {},
        "_validate_config": true,
        "_use_msgpack_checkpoints": false,
        "_torch_grad_scaler_class": null,
        "_torch_lr_scheduler_classes": null,
        "_tf_policy_handles_more_than_one_loss": false,
        "_disable_preprocessor_api": false,
        "_disable_action_flattening": false,
        "_disable_initialize_loss_from_dummy_batch": false,
        "_dont_auto_sync_env_runner_states": false,
        "env_task_fn": -1,
        "enable_connectors": -1,
        "simple_optimizer": false,
        "policy_map_cache": -1,
        "worker_cls": -1,
        "synchronize_filters": -1,
        "enable_async_evaluation": -1,
        "custom_async_evaluation_function": -1,
        "_enable_rl_module_api": -1,
        "auto_wrap_old_gym_envs": -1,
        "always_attach_evaluation_results": -1,
        "replay_sequence_length": null,
        "_disable_execution_plan_api": -1,
        "use_critic": true,
        "use_gae": true,
        "use_kl_loss": true,
        "kl_coeff": 0.2,
        "kl_target": 0.01,
        "vf_loss_coeff": 0.5,
        "entropy_coeff": 0.01,
        "clip_param": 0.2,
        "vf_clip_param": 1.0,
        "entropy_coeff_schedule": null,
        "lr_schedule": null,
        "sgd_minibatch_size": -1,
        "vf_share_layers": -1,
        "differentiable_learner_configs": [
            "DifferentiableLearnerConfig(learner_class=<class 'source.intrinsic_attention_ppo.learners.IntrinsicAttentionPPOLearner.IntrinsicAttentionPPOLearner'>, learner_connector=None, add_default_connectors_to_learner_pipeline=True, is_multi_agent=False, policies_to_update=['default_policy'], lr=0.0003, num_total_minibatches=0, num_epochs=2, minibatch_size=200, shuffle_batch_per_epoch=True)"
        ],
        "__stdout_file__": null,
        "__stderr_file__": null,
        "lambda": 0.95,
        "input": "sampler",
        "policies": {
            "default_policy": [
                null,
                null,
                null,
                null
            ]
        },
        "callbacks": "<class 'ray.rllib.callbacks.callbacks.RLlibCallback'>",
        "create_env_on_driver": false,
        "custom_eval_function": null,
        "framework": "torch"
    },
    "time_since_restore": 259.8202123641968,
    "iterations_since_restore": 5,
    "perf": {
        "cpu_util_percent": 43.324999999999996,
        "ram_util_percent": 65.96578947368421
    }
}