{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "DIR = \"/Users/philipp/Documents/Studium/Informatik/Semester_3/RL/IntrinsicAttention/data/Umbrella/Umbrella_intrinsic_2025-08-11_11-58-04/IntrinsicAttentionPPO_seed42_length50/IntrinsicAttentionPPO_Umbrella_acd0b_00000_0_2025-08-11_11-58-05/result.json\"",
   "id": "54b116f3af0593c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import json\n",
    "\n",
    "import torch\n",
    "\n",
    "data = []\n",
    "with open(DIR, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            data.append(json.loads(line))\n",
    "\n",
    "#mask has shape: [Total Batches, Minibatches per Batch, Intrinsic Reward Output, Source Input]\n",
    "masks = torch.stack(tuple(torch.Tensor(row[\"learners\"][\"IntrinsicAttentionMask\"]) for row in data))  # first object"
   ],
   "id": "444f402813df7b05"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "used_mask = masks[:, -1, 0, :].transpose(1, 0)\n",
    "save_name = \"attention-first_reward\"\n",
    "title = \"First Intr. Rew. Attention on Episode Timesteps\""
   ],
   "id": "2cc709a99eadb1a0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def equalized_to_onehot_with_yfade(\n",
    "        inp: torch.Tensor,\n",
    "        cutoff: float = 0.75,  # after this x-fraction: exactly one-hot per column\n",
    "        hot_row: str | int = \"bottom\",  # \"bottom\", \"top\", or an integer row index\n",
    "        p: float = 2.0,  # column L^p norm target (e.g., 2.0=L2, 1.0=L1)\n",
    "        sharpness: float = 1.6,  # >1 = steeper x-fade (smoothstep exponent)\n",
    "        sigma_min: float = 0.25,  # minimal vertical spread (rows) just before cutoff\n",
    "        sigma_max: float | None = None,  # maximal vertical spread near x=0; None -> 0.5*M\n",
    "        alpha: float = 2.0,  # 2.0=Gaussian, 1.0=Laplacian-like tails\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Build an (M x N) matrix:\n",
    "      • At x=0: equalized columns (row-invariant), column ‖·‖_p = 1.\n",
    "      • 0 < x < cutoff: blend toward a vertical 'bump' centered at hot_row,\n",
    "        with sigma shrinking as x increases (y-fade).\n",
    "      • x >= cutoff: exactly one-hot at hot_row (others = 0).\n",
    "      • Every column is normalized to L^p norm = 1.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - y index 0 is the top row; 'bottom' means row M-1.\n",
    "    - sigma_* are in **row units** (e.g., 1.0 ~ one row).\n",
    "    \"\"\"\n",
    "    assert inp.ndim == 2, \"inp must be 2D (M x N)\"\n",
    "    M, N = inp.shape\n",
    "    device = inp.device\n",
    "    f32 = torch.float32\n",
    "\n",
    "    # hot row index\n",
    "    if isinstance(hot_row, str):\n",
    "        row0 = 0 if hot_row.lower().startswith(\"top\") else (M - 1)\n",
    "    else:\n",
    "        row0 = int(hot_row)\n",
    "        if not (0 <= row0 < M):\n",
    "            raise ValueError(f\"hot_row index {row0} out of range [0, {M - 1}]\")\n",
    "\n",
    "    if sigma_max is None:\n",
    "        sigma_max = max(0.5 * M, 4.0)  # large spread ≈ 'flat' early on\n",
    "\n",
    "    # equalized column so that L^p norm = 1 → each entry = M^{-1/p}\n",
    "    v = float(M) ** (-1.0 / p)\n",
    "    equal_col = torch.full((M, N), v, device=device, dtype=f32)\n",
    "\n",
    "    # one-hot template (norm 1 for any p)\n",
    "    onehot = torch.zeros((M, N), device=device, dtype=f32)\n",
    "    onehot[row0, :] = 1.0\n",
    "\n",
    "    # x progression 0..1\n",
    "    x = torch.linspace(0, 1, N, device=device, dtype=f32)\n",
    "\n",
    "    # smooth progress s(x) from 0→1 over [0, cutoff], then clamp\n",
    "    t = (x / max(1e-8, cutoff)).clamp(0, 1)\n",
    "    t = t.pow(sharpness)\n",
    "    s = t * t * (3 - 2 * t)  # smoothstep\n",
    "\n",
    "    # sigma(x): large → small as x increases (y-fade width shrinks)\n",
    "    sigma_x = (1 - s) * sigma_max + s * sigma_min  # shape (N,)\n",
    "\n",
    "    # vertical distances to hot row\n",
    "    y_idx = torch.arange(M, device=device, dtype=f32).unsqueeze(1)  # (M,1)\n",
    "    d = (y_idx - float(row0)).abs()  # (M,1)\n",
    "\n",
    "    # column-wise vertical bumps (Gauss/Laplace-like with alpha)\n",
    "    # broadcast sigma_x to (1,N)\n",
    "    denom = sigma_x.clamp_min(1e-6).unsqueeze(0)  # (1,N)\n",
    "    bump = torch.exp(-0.5 * (d / denom) ** alpha)  # (M,N)\n",
    "\n",
    "    # Blend equalized ↔ bump for x < cutoff\n",
    "    mat = (1 - s).unsqueeze(0) * equal_col + s.unsqueeze(0) * bump\n",
    "\n",
    "    # Hard switch to exact one-hot for x >= cutoff\n",
    "    hard_mask = (x >= cutoff).unsqueeze(0)  # (1,N)\n",
    "    mat = torch.where(hard_mask, onehot, mat)\n",
    "\n",
    "    # Column-wise L^p normalization to exactly 1\n",
    "    if abs(p - 1.0) < 1e-12:\n",
    "        norms = mat.abs().sum(dim=0, keepdim=True)\n",
    "    else:\n",
    "        norms = mat.abs().pow(p).sum(dim=0, keepdim=True).pow(1.0 / p)\n",
    "    mat = mat / norms.clamp_min(1e-12)\n",
    "\n",
    "    return mat.to(dtype=inp.dtype, device=device)"
   ],
   "id": "9f1e1f5c2bbc16ed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# LUH-style attention heatmap (matplotlib-only, research aesthetic)\n",
    "# - API compatible with your neon_attention_heatmap (same args & returns).\n",
    "# - Defaults: white background, LUH blue sequential colormap, subtle grid.\n",
    "# - No neon/gloss; nice sans-serif font with sensible fallbacks.\n",
    "#\n",
    "# Usage (same as before)\n",
    "# -----\n",
    "# fig, paths = luh_attention_heatmap(\n",
    "#     matrix,\n",
    "#     title=\"Head 3 — Layer 8\", xlabel=\"Key position →\", ylabel=\"Query position →\",\n",
    "#     tokens_x=[...], tokens_y=[...],\n",
    "#     figsize=(10, 8), dpi=220,\n",
    "#     gamma=0.65, clip_percentile=(0, 100),\n",
    "#     render_mode=\"auto\",\n",
    "#     edge_gloss=True,              # now means a subtle light-grey grid\n",
    "#     gloss_strength=0.55,          # grid visibility (0..1), not glossy lines\n",
    "#     annotate=False,\n",
    "#     save_path=\"/mnt/data/attention_luh.png\"\n",
    "# )\n",
    "#\n",
    "from typing import Optional, Sequence, Tuple, Union\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap, PowerNorm, Normalize\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import os, math\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "\n",
    "    _HAS_TORCH = True\n",
    "except Exception:\n",
    "    _HAS_TORCH = False\n",
    "\n",
    "ArrayLike = Union[np.ndarray, \"torch.Tensor\"]\n",
    "\n",
    "\n",
    "def _to_numpy_2d(a: ArrayLike) -> np.ndarray:\n",
    "    if _HAS_TORCH and isinstance(a, torch.Tensor):\n",
    "        a = a.detach().cpu().float().numpy()\n",
    "    a = np.asarray(a, dtype=float)\n",
    "    if a.ndim != 2:\n",
    "        raise ValueError(f\"Expected 2D matrix, got shape {a.shape}.\")\n",
    "    return a\n",
    "\n",
    "\n",
    "def _luh_cmap(kind: str = \"seq\") -> LinearSegmentedColormap:\n",
    "    \"\"\"\n",
    "    LUH corporate palette:\n",
    "      - Uniblau  = #00509B (primary)\n",
    "      - Unigrün  = #C8D317 (accent)\n",
    "    Source: LUH Corporate Identity – Farben.\n",
    "    \"\"\"\n",
    "    if kind == \"div\":\n",
    "        # Blue → white → green (for data centered around a midpoint)\n",
    "        stops = [\n",
    "            (0.00, \"#00509B\"),\n",
    "            (0.50, \"#FFFFFF\"),\n",
    "            (1.00, \"#C8D317\"),\n",
    "        ]\n",
    "        name = \"luh_blue_white_green\"\n",
    "    else:\n",
    "        # Sequential: white → Uniblau (research-friendly, high legibility)\n",
    "        stops = [\n",
    "            (0.00, \"#FFFFFF\"),\n",
    "            (1.00, \"#00509B\"),\n",
    "        ]\n",
    "        name = \"luh_white_to_uniblau\"\n",
    "    return LinearSegmentedColormap.from_list(name, stops)\n",
    "\n",
    "\n",
    "def _resolve_norm(a: np.ndarray, gamma: Optional[float], vmin: Optional[float], vmax: Optional[float], clip_percentile):\n",
    "    if clip_percentile is not None:\n",
    "        lo, hi = clip_percentile\n",
    "        vmin = np.percentile(a, lo) if vmin is None else vmin\n",
    "        vmax = np.percentile(a, hi) if vmax is None else vmax\n",
    "    else:\n",
    "        vmin = np.nanmin(a) if vmin is None else vmin\n",
    "        vmax = np.nanmax(a) if vmax is None else vmax\n",
    "    if not np.isfinite(vmin): vmin = 0.0\n",
    "    if not np.isfinite(vmax): vmax = 1.0\n",
    "    if vmin == vmax: vmax = vmin + 1e-9\n",
    "    if gamma is not None and gamma > 0 and gamma != 1.0:\n",
    "        norm = PowerNorm(gamma=gamma, vmin=vmin, vmax=vmax, clip=True)\n",
    "    else:\n",
    "        norm = Normalize(vmin=vmin, vmax=vmax, clip=True)\n",
    "    return norm, vmin, vmax\n",
    "\n",
    "\n",
    "def luh_attention_heatmap(\n",
    "        matrix: ArrayLike,\n",
    "        title: Optional[str] = \"Attention Heatmap\",\n",
    "        xlabel: str = \"Key position →\",\n",
    "        ylabel: str = \"Query position →\",\n",
    "        tokens_x: Optional[Sequence[str]] = None,  # len == N\n",
    "        tokens_y: Optional[Sequence[str]] = None,  # len == M\n",
    "        figsize: Tuple[float, float] = (10, 8),\n",
    "        dpi: int = 220,\n",
    "        cmap: Optional[LinearSegmentedColormap] = None,  # default set to LUH below\n",
    "        gamma: float = 0.65,  # keep same default as original for identical value mapping\n",
    "        vmin: Optional[float] = None,\n",
    "        vmax: Optional[float] = None,\n",
    "        clip_percentile: Optional[Tuple[float, float]] = (0.0, 100.0),\n",
    "        render_mode: str = \"auto\",  # \"auto\" | \"imshow\" | \"pcolormesh\"\n",
    "        edge_gloss: bool = True,  # now: subtle light-grey grid (no gloss)\n",
    "        gloss_strength: float = 0.55,\n",
    "        annotate: bool = False,\n",
    "        save_path: Optional[str] = None,\n",
    "        tick_max: int = 32,\n",
    "        tick_labelsize: int = 8,\n",
    "        rotate_xticks: int = 90,\n",
    "        background: str = \"#FFFFFF\",  # white canvas (research style)\n",
    "        diverging: bool = False,  # set True for blue↔green around mid\n",
    "):\n",
    "    \"\"\"\n",
    "    Draw a LUH-themed heatmap on a white canvas.\n",
    "    Works for any 2D matrix shape (M x N).\n",
    "    \"\"\"\n",
    "    a = _to_numpy_2d(matrix)\n",
    "    M, N = a.shape\n",
    "\n",
    "    # Use LUH palette unless a custom cmap is supplied\n",
    "    if cmap is None:\n",
    "        cmap = _luh_cmap(\"div\" if diverging else \"seq\")\n",
    "\n",
    "    norm, vmin, vmax = _resolve_norm(a, gamma, vmin, vmax, clip_percentile)\n",
    "\n",
    "    # Font & styling (contained to this function)\n",
    "    rc = {\n",
    "        \"font.family\": [\"DejaVu Sans\", \"Arial\", \"Helvetica\"],\n",
    "        \"axes.titleweight\": \"semibold\",\n",
    "        \"axes.titlesize\": 14,\n",
    "        \"axes.labelsize\": 11,\n",
    "        \"xtick.labelsize\": tick_labelsize,\n",
    "        \"ytick.labelsize\": tick_labelsize,\n",
    "    }\n",
    "\n",
    "    with plt.rc_context(rc):\n",
    "        fig = plt.figure(figsize=figsize, dpi=dpi)\n",
    "        fig.patch.set_facecolor(background)\n",
    "        ax = plt.gca()\n",
    "        ax.set_facecolor(background)\n",
    "\n",
    "        total_cells = M * N\n",
    "        if render_mode == \"auto\":\n",
    "            render_mode = \"pcolormesh\" if total_cells <= 20000 else \"imshow\"\n",
    "\n",
    "        grid_color = (0.85, 0.85, 0.85, min(0.8, 0.25 + 0.6 * gloss_strength))  # subtle neutral grey\n",
    "\n",
    "        # Main image\n",
    "        if render_mode == \"imshow\":\n",
    "            im = ax.imshow(a, origin=\"upper\", aspect=\"equal\", interpolation=\"nearest\",\n",
    "                           cmap=cmap, norm=norm)\n",
    "            if edge_gloss:\n",
    "                ax.set_xticks(np.arange(-0.5, N, 1), minor=True)\n",
    "                ax.set_yticks(np.arange(-0.5, M, 1), minor=True)\n",
    "                ax.grid(which=\"minor\", linestyle=\"-\", linewidth=0.6, color=grid_color)\n",
    "                ax.tick_params(axis=\"both\", which=\"both\", length=0)\n",
    "        else:\n",
    "            x = np.arange(N + 1)\n",
    "            y = np.arange(M + 1)\n",
    "            if edge_gloss:\n",
    "                ax.pcolormesh(x, y, a, cmap=cmap, norm=norm, shading=\"flat\",\n",
    "                              edgecolors=grid_color, linewidth=0.6)\n",
    "                im = ax.collections[-1]\n",
    "            else:\n",
    "                im = ax.pcolormesh(x, y, a, cmap=cmap, norm=norm, shading=\"flat\",\n",
    "                                   edgecolors=\"none\", linewidth=0.0)\n",
    "\n",
    "        # Labels & title (dark text for legibility)\n",
    "        if title:\n",
    "            ax.set_title(title, color=\"#111111\", pad=12)\n",
    "        ax.set_xlabel(xlabel, color=\"#111111\", labelpad=6)\n",
    "        ax.set_ylabel(ylabel, color=\"#111111\", labelpad=6)\n",
    "\n",
    "        # Tick labeling\n",
    "        ax.tick_params(axis=\"both\", labelcolor=\"#111111\", length=0)\n",
    "        # X ticks\n",
    "        if tokens_x is not None and len(tokens_x) == N:\n",
    "            step_x = max(1, int(math.ceil(N / tick_max)))\n",
    "            idx = list(range(0, N, step_x))\n",
    "            if idx[-1] != N - 1:\n",
    "                idx.append(N - 1)\n",
    "            ax.set_xticks(idx)\n",
    "            ax.set_xticklabels([str(tokens_x[i]) for i in idx], rotation=rotate_xticks, ha=\"center\", va=\"top\")\n",
    "        else:\n",
    "            ax.xaxis.set_major_locator(MaxNLocator(nbins=min(tick_max, 12), integer=True))\n",
    "        # Y ticks\n",
    "        if tokens_y is not None and len(tokens_y) == M:\n",
    "            step_y = max(1, int(math.ceil(M / tick_max)))\n",
    "            idy = list(range(0, M, step_y))\n",
    "            if idy[-1] != M - 1:\n",
    "                idy.append(M - 1)\n",
    "            ax.set_yticks(idy)\n",
    "            ax.set_yticklabels([str(tokens_y[i]) for i in idy])\n",
    "        else:\n",
    "            ax.yaxis.set_major_locator(MaxNLocator(nbins=min(tick_max, 12), integer=True))\n",
    "\n",
    "        # Remove spines for a clean research look\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_visible(False)\n",
    "\n",
    "        # Colorbar (neutral text & ticks)\n",
    "        cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "        cbar.outline.set_visible(False)\n",
    "        cbar.ax.tick_params(labelsize=8, colors=\"#111111\")\n",
    "        cbar.ax.yaxis.set_tick_params(color=\"#111111\")\n",
    "        cbar.ax.set_ylabel(\"Intensity\", rotation=270, labelpad=14, color=\"#111111\", fontsize=9)\n",
    "\n",
    "        # Optional per-cell annotations (small matrices)\n",
    "        if annotate and total_cells <= 900:\n",
    "            for i in range(M):\n",
    "                for j in range(N):\n",
    "                    val = a[i, j]\n",
    "                    if np.isfinite(val):\n",
    "                        ax.text(j if render_mode == \"imshow\" else j + 0.5,\n",
    "                                i if render_mode == \"imshow\" else i + 0.5,\n",
    "                                f\"{val:.2f}\", ha=\"center\", va=\"center\", fontsize=6, color=\"#111111\", alpha=0.85)\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        paths = None\n",
    "        if save_path:\n",
    "            fig.savefig(save_path, bbox_inches=\"tight\", facecolor=fig.get_facecolor(), dpi=max(dpi, 300))\n",
    "            root, _ = os.path.splitext(save_path)\n",
    "            pdf_path = root + \".pdf\"\n",
    "            fig.savefig(pdf_path, bbox_inches=\"tight\", facecolor=fig.get_facecolor())\n",
    "            paths = (save_path, pdf_path)\n",
    "\n",
    "        return fig, paths"
   ],
   "id": "1cb04ff6d226355a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "used_time_step = 49  # 0 indexed, 50 is the last \"Add one T\" Step\n",
    "fig, paths = luh_attention_heatmap(\n",
    "    used_mask,\n",
    "    title=f\"{title} • Umbrella Env\",\n",
    "    xlabel=\"Training Rounds\",\n",
    "    ylabel=\"Episode Input Step\",\n",
    "    tokens_x=[f\"k{j}\" for j in range(used_mask.shape[0])],\n",
    "    tokens_y=[f\"q{i}\" for i in range(used_mask.shape[1])],\n",
    "    figsize=(5, 5),\n",
    "    dpi=240,\n",
    "    gamma=0.55,\n",
    "    clip_percentile=(0.5, 99.5),\n",
    "    render_mode=\"auto\",\n",
    "    edge_gloss=True,\n",
    "    gloss_strength=0.7,\n",
    "    annotate=False,\n",
    "    save_path=f\"../images/{save_name}.png\",\n",
    "    tick_max=36,\n",
    "    rotate_xticks=90\n",
    ")"
   ],
   "id": "397c4830870acd7e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "template = equalized_to_onehot_with_yfade(\n",
    "    used_mask,\n",
    "    cutoff=0.85,  # fully one-hot in the last 25% of columns\n",
    "    hot_row=\"bottom\",  # bottom-right will be the final hot pixel\n",
    "    p=2.0,  # L2 per-column norm\n",
    "    sharpness=1.6,\n",
    "    sigma_min=0.2,  # ~sub-row width as it approaches one-hot\n",
    "    sigma_max=None,  # auto based on M\n",
    "    alpha=2.0  # Gaussian; try 1.0 for heavier tails\n",
    ")\n",
    "\n",
    "fig, paths = luh_attention_heatmap(\n",
    "    template,\n",
    "    title=f\"Optimal • {title} • Umbrella Env\",\n",
    "    xlabel=\"Training Rounds\",\n",
    "    ylabel=\"Episode Input Step\",\n",
    "    tokens_x=[f\"k{j}\" for j in range(template.shape[0])],\n",
    "    tokens_y=[f\"q{i}\" for i in range(template.shape[1])],\n",
    "    figsize=(5, 5),\n",
    "    dpi=240,\n",
    "    gamma=0.55,\n",
    "    clip_percentile=(0.5, 99.5),\n",
    "    render_mode=\"auto\",\n",
    "    edge_gloss=True,\n",
    "    gloss_strength=0.7,\n",
    "    annotate=False,\n",
    "    save_path=f\"../images/OPTIMAL_{save_name}.png\",\n",
    "    tick_max=36,\n",
    "    rotate_xticks=90\n",
    ")"
   ],
   "id": "a08827d517809935"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "442d2aa3b5fde9c2"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
